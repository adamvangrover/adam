import openai

class LLMPlugin:
    def __init__(self, config):
        """
        Initializes the LLM plugin with the provided configuration.

        :param config: Configuration dictionary containing necessary settings like API keys.
        """
        self.api_key = config.get("api_key", "")
        self.model = config.get("model", "gpt-4")
        
        if not self.api_key:
            raise ValueError("API Key is required for the LLM plugin.")
        
        openai.api_key = self.api_key  # Set the OpenAI API key for API calls

    def generate_content(self, prompt, task_description=None):
        """
        Generates content using the LLM based on the provided prompt.
        
        :param prompt: The main prompt to send to the LLM.
        :param task_description: (Optional) A description of the task for additional context.
        
        :return: Generated content from the LLM.
        """
        try:
            # Adding task description to the prompt if provided
            if task_description:
                prompt = f"{task_description}: {prompt}"

            # Make an API call to OpenAI's GPT model (or any other LLM you're using)
            response = openai.Completion.create(
                model=self.model,
                prompt=prompt,
                max_tokens=200,  # Set the maximum number of tokens
                temperature=0.7,  # Control randomness in the output
                n=1,  # Number of completions to generate
                stop=None,  # No specific stopping condition
            )

            # Extract the text response
            generated_text = response.choices[0].text.strip()
            return generated_text

        except Exception as e:
            print(f"Error generating content with LLM: {e}")
            return None

    def summarize_text(self, text):
        """
        Summarizes the provided text using the LLM.

        :param text: The text to summarize.
        :return: Summary of the provided text.
        """
        prompt = f"Summarize the following text: {text}"
        return self.generate_content(prompt)

    def answer_question(self, question, context):
        """
        Answers a specific question based on a given context using the LLM.

        :param question: The question to answer.
        :param context: The context to use for answering the question.
        :return: The answer generated by the LLM.
        """
        prompt = f"Context: {context}\nQuestion: {question}\nAnswer:"
        return self.generate_content(prompt)

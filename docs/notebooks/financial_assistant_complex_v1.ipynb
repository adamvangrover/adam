{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Financial Document Analysis Assistant (v13 - Conceptual)\n",
    "\n",
    "**Goal:** Extract, analyze, and report on financial information from various documents with user-selectable strategies and AI enhancements.\n",
    "\n",
    "**Structure:** This notebook is divided into logical cells:\n",
    "1.  **Setup & Configuration:** Imports, constants, global state.\n",
    "2.  **Text Extraction Helpers:** Functions to get text from PDF, DOCX, URL, TXT.\n",
    "3.  **Parsing Strategy Helpers:** Functions for Regex, Standard QA, Chunked QA, Table (Placeholder), Hybrid (Placeholder), NER (Placeholder).\n",
    "4.  **Estimation & AI Analysis Helpers:** Functions for estimations, text analysis (Summ/ZS/Sent), advanced placeholders.\n",
    "5.  **Report Generation Helpers:** Functions for HTML report, NLG (Placeholder), Charting (Placeholder), Export (Placeholders).\n",
    "6.  **Model Loading Trigger:** Button to explicitly load AI models.\n",
    "7.  **UI Widget Setup:** Definition of all `ipywidgets`.\n",
    "8.  **UI Event Handlers:** Functions triggered by button clicks, uploads, etc.\n",
    "9.  **UI Layout & Display:** Assembling and displaying the final UI.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run Cell 1 first to set up imports and configurations.\n",
    "2. Run Cells 2-5 to define helper functions.\n",
    "3. Run Cell 6 and click the button to load AI models (requires internet, takes time).\n",
    "4. Run Cell 7 to define UI widgets.\n",
    "5. Run Cell 8 to define UI event handlers.\n",
    "6. Run Cell 9 to display the application UI.\n",
    "7. Interact with the UI (load doc, parse, verify, generate report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 1: Setup & Configuration --%%\n",
    "# --- Imports ---\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import math, re, time, warnings, html, os, io\n",
    "from collections import defaultdict\n",
    "import requests \n",
    "import pandas as pd \n",
    "\n",
    "# --- Optional Libs (handle import errors) ---\n",
    "PDF_AVAILABLE, DOCX_AVAILABLE, HTML_AVAILABLE, CAMELOT_AVAILABLE, PLT_AVAILABLE, FPDF_AVAILABLE, TOKENIZER_AVAILABLE = False, False, False, False, False, False, False\n",
    "try: import pypdf2; PDF_AVAILABLE=True; print(\"INFO: pypdf2 found for PDF text.\")\n",
    "except ImportError: print(\"WARN: pypdf2 not found, PDF upload disabled.\")\n",
    "try: import docx; DOCX_AVAILABLE=True; print(\"INFO: python-docx found for DOCX text.\")\n",
    "except ImportError: print(\"WARN: python-docx not found, DOCX upload disabled.\")\n",
    "try: from bs4 import BeautifulSoup; HTML_AVAILABLE=True; print(\"INFO: BeautifulSoup found for HTML parsing.\")\n",
    "except ImportError: print(\"WARN: BeautifulSoup not found, HTML/URL parsing limited.\")\n",
    "try: import camelot; CAMELOT_AVAILABLE=True; print(\"INFO: camelot-py found for PDF tables (experimental).\")\n",
    "except ImportError: print(\"WARN: camelot-py not found, PDF table extraction disabled.\")\n",
    "try: import matplotlib.pyplot as plt; from io import BytesIO; import base64; PLT_AVAILABLE=True; print(\"INFO: Matplotlib found.\")\n",
    "except ImportError: print(\"WARN: Matplotlib not found, charts disabled.\")\n",
    "try: from fpdf import FPDF; FPDF_AVAILABLE=True; print(\"INFO: fpdf2 found for PDF export.\")\n",
    "except ImportError: print(\"WARN: fpdf2 not found, PDF export disabled.\")\n",
    "try: from transformers import AutoTokenizer; TOKENIZER_AVAILABLE=True; print(\"INFO: AutoTokenizer found.\")\n",
    "except ImportError: print(\"WARN: AutoTokenizer not found.\")\n",
    "    \n",
    "# --- Config Constants ---\n",
    "# Model names \n",
    "MODEL_QA = \"deepset/roberta-base-squad2\" \n",
    "MODEL_SUMMARIZER = \"sshleifer/distilbart-cnn-12-6\"\n",
    "MODEL_ZERO_SHOT = \"facebook/bart-large-mnli\"\n",
    "MODEL_SENTIMENT = \"ProsusAI/finbert\"\n",
    "MODEL_NLG = \"gpt2\" # Example, choose appropriate model\n",
    "\n",
    "# Parsing Strategy Options & Default\n",
    "PARSE_STRATEGY_STANDARD = \"Standard AI QA (Fastest AI)\"\n",
    "PARSE_STRATEGY_CHUNKED = \"Full Document AI QA (Slow, Experimental)\"\n",
    "PARSE_STRATEGY_HYBRID = \"Hybrid (AI Text + Regex/Table Numbers)\"\n",
    "PARSE_STRATEGY_TABLE = \"Table Extraction First (Experimental)\" \n",
    "PARSE_STRATEGY_REGEX = \"Regex Only (Fastest, Numbers Only)\"\n",
    "PARSE_STRATEGY_NER = \"Financial NER/RE (Future)\" # Placeholder\n",
    "DEFAULT_PARSE_STRATEGY = PARSE_STRATEGY_STANDARD\n",
    "\n",
    "# QA Model Configuration\n",
    "QA_CONTEXT_TRUNCATION_CHARS = 4000 \n",
    "QA_CHUNK_SIZE_CHARS = 2500       \n",
    "QA_CHUNK_OVERLAP_CHARS = 500      \n",
    "QA_SCORE_THRESHOLD = 0.03 # Lowered threshold        \n",
    "\n",
    "# Zero-Shot Classification Config\n",
    "ZERO_SHOT_LABELS = [\"Volume/Demand\", \"Pricing/Mix\", \"Cost Control\", \"M&A\", \"FX/Rates\", \"Capex\", \"WC\", \"Debt/Financing\", \"Product/Service\", \"Market/Comp.\", \"Inflation\", \"Supply Chain\", \"Restructuring\"]\n",
    "ZERO_SHOT_CONFIDENCE_THRESHOLD = 0.40 \n",
    "\n",
    "# Text Analysis Config\n",
    "TEXT_ANALYSIS_MAX_CHARS_ZS = 500 \n",
    "TEXT_ANALYSIS_MAX_CHARS_SENTIMENT = 450 \n",
    "\n",
    "# --- Dependency Check for Transformers ---\n",
    "TRANSFORMERS_AVAILABLE = False\n",
    "try:\n",
    "    try: import torch; print(\"INFO: PyTorch backend found.\")\n",
    "    except ImportError: import tensorflow; print(\"INFO: TensorFlow backend found.\")\n",
    "    from transformers import pipeline\n",
    "    _ = pipeline('sentiment-analysis') # Basic check\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "    print(\"INFO: 'transformers' library seems functional.\")\n",
    "except ImportError as e: print(f\"WARNING: Dependency issue ({e}). AI features disabled.\")\n",
    "except Exception as e: print(f\"WARNING: Transformer init failed: {e}. AI features disabled.\")\n",
    "\n",
    "# --- Global State --- Use a class for cleaner state management\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.document_name = None\n",
    "        self.document_text = None\n",
    "        self.document_tables = [] # List of pandas DataFrames\n",
    "        self.parsed_data = defaultdict(lambda: None) # Holds data from parsing/estimation\n",
    "        self.estimation_log = []\n",
    "        self.analysis_results = {} # Holds results from text analysis module\n",
    "        self.current_report_html = \"\"\n",
    "        self.pipelines = {\"qa\": None, \"summarizer\": None, \"zero_shot\": None, \"sentiment\": None, \"text-generation\": None} # Add NLG pipe\n",
    "        self.models_loaded = False\n",
    "        self.model_load_error = False\n",
    "        self.qa_tokenizer = None\n",
    "\n",
    "app_state = AppState() # Instantiate the state object\n",
    "\n",
    "# --- Status Widgets --- (Should be defined in Cell 7, but declare here for early use if needed)\n",
    "load_status_label = widgets.HTML(value=\"Status: Models not loaded.\")\n",
    "parse_status_label = widgets.HTML(value=\"Status: Ready.\")\n",
    "analysis_status_label = widgets.HTML(value=\"Status: Ready.\")\n",
    "custom_qa_status_label = widgets.HTML(value=\"\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='transformers') \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "print(\"-\" * 20, \"Cell 1: Setup Complete\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 2: Helper Functions - Text Extraction & Formatting --%%\n",
    "\n",
    "def extract_text_from_pdf(file_content):\n",
    "    \"\"\"Extracts text from PDF file content (bytes). Requires pypdf2.\"\"\"\n",
    "    if not PDF_AVAILABLE: return \"Error: pypdf2 library not installed.\"\n",
    "    try:\n",
    "        pdf_reader = pypdf2.PdfReader(io.BytesIO(file_content))\n",
    "        text = \"\".join(page.extract_text() + \"\\n\" for page in pdf_reader.pages)\n",
    "        return text if text else \"Warning: No text extracted from PDF (maybe image-based?).\"\n",
    "    except Exception as e: return f\"Error extracting PDF text: {e}\"\n",
    "\n",
    "def extract_text_from_docx(file_content):\n",
    "    \"\"\"Extracts text from DOCX file content (bytes). Requires python-docx.\"\"\"\n",
    "    if not DOCX_AVAILABLE: return \"Error: python-docx library not installed.\"\n",
    "    try:\n",
    "        doc = docx.Document(io.BytesIO(file_content))\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e: return f\"Error extracting DOCX text: {e}\"\n",
    "\n",
    "def fetch_and_extract_html(url):\n",
    "    \"\"\"Fetches URL and extracts main text content using BeautifulSoup.\"\"\"\n",
    "    if not HTML_AVAILABLE: return \"Error: BeautifulSoup library not installed.\", None\n",
    "    html_content = \"\"\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'} # Basic user agent\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status() # Raise error for bad status codes\n",
    "        html_content = response.text # Get raw HTML for table extraction later\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        for script_or_style in soup([\"script\", \"style\"]): script_or_style.decompose()\n",
    "        text = soup.get_text(separator='\\n', strip=True)\n",
    "        return text if text else \"Warning: No text extracted from URL.\", html_content\n",
    "    except Exception as e: return f\"Error fetching/parsing URL: {e}\", html_content\n",
    "\n",
    "def extract_text_from_txt(file_content):\n",
    "    \"\"\"Extracts text from TXT file content (bytes), guessing encoding.\"\"\"\n",
    "    try:\n",
    "        for encoding in ['utf-8', 'latin-1', 'cp1252']:\n",
    "            try: return file_content.decode(encoding)\n",
    "            except UnicodeDecodeError: continue\n",
    "        return \"Error: Could not decode TXT file with common encodings.\"\n",
    "    except Exception as e: return f\"Error reading TXT file: {e}\"\n",
    "\n",
    "# --- Formatting Functions ---\n",
    "def format_currency(v): \n",
    "    if not isinstance(v,(int,float)) or v is None or math.isnan(v) or math.isinf(v): return \"$N/A\"\n",
    "    try: v_mm = v / 1e6; return f\"${v_mm:,.1f}mm\" if abs(v_mm) >= 0.05 else \"$0.0mm\"\n",
    "    except: return \"$N/A\"\n",
    "def format_percentage(v): \n",
    "    if not isinstance(v,(int,float)) or v is None or math.isnan(v): return \"N/A%\"\n",
    "    try: return \"Infinite %\" if math.isinf(v) else f\"{v:.1f}%\"\n",
    "    except: return \"N/A%\"\n",
    "def format_leverage(v): \n",
    "    if not isinstance(v,(int,float)) or v is None or math.isnan(v) or math.isinf(v): return \"N/Ax\"\n",
    "    try: return f\"{v:.1f}x\"\n",
    "    except: return \"N/Ax\"\n",
    "\n",
    "print(\"-\" * 20, \"Cell 2: Text Extraction & Formatting Helpers Defined\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 3: Helper Functions - Parsing Strategies --%%\n",
    "\n",
    "# --- Regex Parsing Functions ---\n",
    "def extract_financial_figure_regex(text, keywords):\n",
    "    \"\"\"Fallback: Uses Regex to find likely financial figure near keywords.\"\"\"\n",
    "    num_pattern = r'[\\$€£]?\\s?\\(?(?P<num>\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\)?\\s*(?P<unit>million|billion|thousand|mn|bn|k)?\\b'\n",
    "    window = 250; figures = [] \n",
    "    for kw in keywords:\n",
    "        try:\n",
    "            for m in re.finditer(r'\\b' + re.escape(kw) + r'\\b', text, re.IGNORECASE):\n",
    "                s, _ = m.span(); start = max(0, s - window); end = min(len(text), s + window); seg = text[start:end]\n",
    "                for nm in re.finditer(num_pattern, seg, re.IGNORECASE):\n",
    "                    v_str = nm.group('num'); unit_str = nm.group('unit'); ns, _ = nm.span()\n",
    "                    neg = (ns > 0 and seg[ns - 1] == '-') or nm.group(0).startswith('(')\n",
    "                    try: \n",
    "                        v = float(v_str.replace(',', '')); v = -v if neg else v\n",
    "                        unit = unit_str.lower() if unit_str else \"\"; v *= 1e3 if 'bil' in unit or unit=='bn' else (1e-3 if 'tho' in unit or unit=='k' else 1)\n",
    "                        figures.append({'value': v, 'pos': start + ns})\n",
    "                    except ValueError: continue\n",
    "        except Exception as e: print(f\"Regex warn kw='{kw}': {e}\"); continue \n",
    "    if not figures: return None\n",
    "    first_kw_m = re.search(r'\\b' + re.escape(keywords[0]) + r'\\b', text, re.IGNORECASE); kw_pos = first_kw_m.start() if first_kw_m else 0\n",
    "    after = [f for f in figures if f['pos'] >= kw_pos]; best = min(after if after else figures, key=lambda f: abs(f['pos'] - kw_pos), default=None)\n",
    "    return best['value'] if best else None\n",
    "\n",
    "def _parse_regex_only(text, status_widget):\n",
    "    \"\"\"Implements the Regex Only parsing strategy.\"\"\"\n",
    "    status_widget.value = \"<span style='color: blue;'>Status: Running Regex...</span>\"; print(\"Regex Only Strategy...\")\n",
    "    extracted = defaultdict(lambda: None) \n",
    "    # Define keywords for each metric\n",
    "    kw_map = {'revenue_current': [\"revenue\", \"total revenue\", \"net sales\"], 'ebitda_current': [\"ebitda\", \"adjusted ebitda\"], 'fcf_current': [\"free cash flow\", \"fcf\"], 'cogs_current': [\"cost of goods\", \"cogs\"], 'opex_current': [\"operating expenses\", \"opex\", \"sg&a\"], 'da_current': [\"depreciation\", \"amortization\"], 'op_income_current': [\"operating income\", \"ebit\"], 'ocf_current': [\"operating activities\", \"cash from operations\"], 'capex_current': [\"capital expenditure\", \"capex\"], 'debt_total_current': [\"total debt\", \"borrowings\"], 'leverage_current': [\"leverage ratio\", \"net debt to ebitda\"]}\n",
    "    for key, kws in kw_map.items(): extracted[key] = extract_financial_figure_regex(text, kws)\n",
    "    print(\"Regex Only Notice: Qualitative & prior periods need manual input.\")\n",
    "    status_widget.value = \"<span style='color: green;'>Status: Regex Complete.</span>\"\n",
    "    return extracted, \"Regex Only\"\n",
    "\n",
    "# --- AI QA Parsing Functions ---\n",
    "def parse_financial_answer(ans, is_qual=False):\n",
    "    \"\"\"Parses QA answer: text if qualitative, else number (in millions).\"\"\"\n",
    "    # ... (Implementation from previous version) ...\n",
    "    if not ans: return None\n",
    "    if is_qual: return ans.strip() \n",
    "    txt = ans.lower().replace('approx.','').strip(); txt = re.sub(r'[\\$€£]', '', txt).strip(); txt = re.sub(r'\\s+(dollars|euros|pounds)\\b','', txt); txt = txt.replace('(','-').replace(')','') \n",
    "    num_pat = r'([-+]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(million|billion|thousand|mn|bn|k)?'; m = re.search(num_pat, txt)\n",
    "    if not m: m = re.search(r'([-+]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)', txt); v_str = m.group(1) if m else None; unit = \"\" \n",
    "    else: v_str, u_m = m.groups(); unit = u_m if u_m else \"\"\n",
    "    if not v_str: return None\n",
    "    try: v = float(v_str.replace(',', ''))\n",
    "    except: return None \n",
    "    unit = unit.lower(); v *= 1e3 if 'bil' in unit or unit=='bn' else (1e-3 if 'tho' in unit or unit=='k' else 1)\n",
    "    return v\n",
    "\n",
    "def _run_qa_on_context(qa_pipe, questions, context, status_widget, context_label=\"context\"):\n",
    "    \"\"\"Runs QA questions against a single context string, returns best results.\"\"\"\n",
    "    # ... (Implementation from previous version) ...\n",
    "    extracted = defaultdict(lambda: None)\n",
    "    q_total = sum(len(v) for v in questions.values()); q_ran = 0\n",
    "    print(f\"Running {q_total} QA variations on {context_label}...\")\n",
    "    for key, q_list in questions.items():\n",
    "        best_ans = None; best_score = -1; is_qual = \"text\" in key \n",
    "        for q_idx, q in enumerate(q_list):\n",
    "            q_ran += 1; \n",
    "            if (q_ran % 10 == 0): status_widget.value = f\"<span style='color: blue;'>Status: QA ({q_ran}/{q_total} in {context_label})...</span>\"\n",
    "            try:\n",
    "                res = qa_pipe(question=q, context=context, handle_impossible_answer=True); ans, score = res.get('answer'), res.get('score', 0)\n",
    "                if ans and score > QA_SCORE_THRESHOLD: \n",
    "                    parsed = parse_financial_answer(ans, is_qualitative=is_qual)\n",
    "                    if parsed is not None and score > best_score: best_score = score; best_ans = parsed; \n",
    "            except Exception as e: print(f\"QA Error q='{q}': {e}\")\n",
    "            time.sleep(0.01) \n",
    "        extracted[key] = best_ans \n",
    "    return extracted\n",
    "\n",
    "def _get_qa_questions():\n",
    "    \"\"\"Returns the dictionary of questions for the QA model.\"\"\"\n",
    "    # ... (Implementation from previous version with refined questions) ...\n",
    "    q = defaultdict(list)\n",
    "    q_fin = ['revenue_current', 'revenue_prior', 'ebitda_current', 'ebitda_prior', 'fcf_current', 'fcf_prior', 'cogs_current', 'cogs_prior', 'opex_current', 'opex_prior', 'da_current', 'da_prior', 'op_income_current', 'op_income_prior', 'ocf_current', 'ocf_prior', 'capex_current', 'capex_prior', 'debt_total_current', 'leverage_current']\n",
    "    q_qual = ['revenue_drivers_text', 'ebitda_drivers_text', 'fcf_drivers_text', 'leverage_drivers_text']\n",
    "    for k in q_fin + q_qual: q[k].append(f\"What was the {k.replace('_', ' ').replace('text','explanation').replace('current','current period').replace('prior','prior year period')}?\")\n",
    "    q['revenue_current'].extend([\"Net sales current period?\", \"Latest revenue figure?\", \"Total revenue?\"]); q['revenue_prior'].extend([\"Net sales prior year?\", \"Comparable prior revenue?\", \"Revenue last year?\"])\n",
    "    q['ebitda_current'].extend([\"Adjusted EBITDA current period?\", \"Latest EBITDA?\", \"How much was EBITDA?\"]); q['ebitda_prior'].extend([\"Adjusted EBITDA prior year?\", \"Prior EBITDA?\", \"EBITDA last year?\"])\n",
    "    q['fcf_current'].extend([\"Free cash flow current period?\", \"Latest FCF?\"]); q['fcf_prior'].extend([\"Free cash flow prior year?\", \"Prior FCF?\"])\n",
    "    q['revenue_drivers_text'].extend([\"Explain revenue change.\", \"Factors impacting sales?\", \"What drove revenue?\", \"Describe revenue performance.\"])\n",
    "    q['ebitda_drivers_text'].extend([\"Explain EBITDA change.\", \"What affected margins?\", \"Drivers for profitability?\", \"Describe EBITDA performance.\"])\n",
    "    q['fcf_drivers_text'].extend([\"Explain FCF change.\", \"Reasons for cash flow?\", \"What impacted FCF?\", \"Describe free cash flow drivers.\"])\n",
    "    q['leverage_drivers_text'].extend([\"Explain leverage change.\", \"Reasons for net debt change?\", \"Factors affecting debt?\", \"Describe leverage drivers.\"])\n",
    "    q['opex_current'].append(\"SG&A expense current period?\"); q['opex_prior'].append(\"SG&A expense prior year?\")\n",
    "    q['ocf_current'].append(\"Cash flow from operations current period?\"); q['ocf_prior'].append(\"Cash flow from operations prior year?\")\n",
    "    q['capex_current'].append(\"Capital expenditures current period?\"); q['capex_prior'].append(\"Capital expenditures prior year?\")\n",
    "    q['leverage_current'].append(\"Net debt to EBITDA ratio end of period?\")\n",
    "    return q\n",
    "\n",
    "def _parse_standard_qa(text, status_widget):\n",
    "    \"\"\"Implements Standard AI QA strategy (runs on truncated text).\"\"\"\n",
    "    # ... (Implementation from previous version) ...\n",
    "    status_widget.value = \"<span style='color: blue;'>Status: Running Standard AI QA...</span>\"; print(\"Standard AI QA Strategy...\")\n",
    "    qa_pipe = app_state.pipelines.get(\"qa\"); assert qa_pipe, \"QA model not loaded.\"\n",
    "    text_context = text[:QA_CONTEXT_TRUNCATION_CHARS] \n",
    "    questions = _get_qa_questions()\n",
    "    extracted_data = _run_qa_on_context(qa_pipe, questions, text_context, status_widget, context_label=\"truncated context\") \n",
    "    print(f\"Standard AI QA Finished. Found {len([v for v in extracted_data.values() if v is not None])} potential answers.\")\n",
    "    status_widget.value = \"<span style='color: green;'>Status: Standard AI QA Complete.</span>\"\n",
    "    return extracted_data, PARSE_STRATEGY_STANDARD\n",
    "\n",
    "def _create_text_chunks(text, chunk_chars, overlap_chars):\n",
    "    \"\"\"Splits text into potentially overlapping chunks.\"\"\"\n",
    "    # ... (Implementation from previous version - consider token-based if tokenizer available) ...\n",
    "    chunks = []; start = 0\n",
    "    if app_state.qa_tokenizer: # Use tokenizer if available\n",
    "        print(\"Using tokenizer for chunking...\")\n",
    "        max_tokens = app_state.qa_tokenizer.model_max_length - 50 # Buffer\n",
    "        tokens = app_state.qa_tokenizer(text, return_offsets_mapping=True, max_length=max_tokens*20, truncation=False) \n",
    "        offsets = tokens['offset_mapping']; current_chunk_start_idx = 0\n",
    "        while current_chunk_start_idx < len(offsets):\n",
    "            end_token_idx = min(current_chunk_start_idx + max_tokens -1, len(offsets) - 1)\n",
    "            chunk_end_char = offsets[end_token_idx][1]; chunk_start_char = offsets[current_chunk_start_idx][0]\n",
    "            chunks.append(text[chunk_start_char:chunk_end_char])\n",
    "            overlap_tokens = max_tokens // 4; next_start_token_idx = current_chunk_start_idx + max_tokens - overlap_tokens\n",
    "            current_chunk_start_idx = max(current_chunk_start_idx + 1, next_start_token_idx) \n",
    "            if current_chunk_start_idx >= len(offsets): break \n",
    "    else: # Fallback character chunking\n",
    "        print(\"Using character-based chunking...\")\n",
    "        while True:\n",
    "            end = start + chunk_chars; chunks.append(text[start:end])\n",
    "            start += chunk_chars - overlap_chars \n",
    "            if end >= len(text): break \n",
    "    return chunks\n",
    "    \n",
    "def _parse_chunked_qa(text, status_widget):\n",
    "    \"\"\"Implements Full Document AI QA strategy using overlapping chunks.\"\"\"\n",
    "    # ... (Implementation from previous version - needs careful score aggregation) ...\n",
    "    status_widget.value = \"<span style='color: blue;'>Status: Running Full Doc QA (Chunking)... SLOW!</span>\"; print(f\"Full Doc AI QA Strategy...\")\n",
    "    qa_pipe = app_state.pipelines.get(\"qa\"); assert qa_pipe, \"QA model not loaded.\"\n",
    "    text_chunks = _create_text_chunks(text, QA_CHUNK_SIZE_CHARS, QA_CHUNK_OVERLAP_CHARS)\n",
    "    print(f\"Created {len(text_chunks)} chunks. Processing...\")\n",
    "    questions = _get_qa_questions()\n",
    "    agg_res = defaultdict(lambda: {'answer': None, 'score': -1}) \n",
    "    total_q_est = sum(len(v) for v in questions.values()) * len(text_chunks); print(f\"Est. total QA calls: ~{total_q_est} (SLOW!)\")\n",
    "    for i, chunk_ctx in enumerate(text_chunks):\n",
    "        print(f\"\\nProcessing Chunk {i+1}/{len(text_chunks)}...\")\n",
    "        status_widget.value = f\"<span style='color: blue;'>Status: Chunk {i+1}/{len(text_chunks)}... (SLOW)</span>\"\n",
    "        q_total_chunk = sum(len(v) for v in questions.values()); q_ran_chunk = 0\n",
    "        for key, q_list in questions.items():\n",
    "            is_qual = \"text\" in key\n",
    "            for q_idx, q in enumerate(q_list):\n",
    "                q_ran_chunk += 1\n",
    "                if (q_ran_chunk % 10 == 0): status_widget.value = f\"<span style='color: blue;'>Status: Chunk {i+1} QA ({q_ran_chunk}/{q_total_chunk})...</span>\"\n",
    "                try:\n",
    "                    res = qa_pipe(question=q, context=chunk_ctx, handle_impossible_answer=True); ans, score = res.get('answer'), res.get('score', 0)\n",
    "                    if ans and score > QA_SCORE_THRESHOLD: \n",
    "                        parsed = parse_financial_answer(ans, is_qualitative=is_qual)\n",
    "                        if parsed is not None and score > agg_res[key]['score']: \n",
    "                            agg_res[key]['score'] = score; agg_res[key]['answer'] = parsed\n",
    "                            # print(f\"    -> Updated best for '{key}' from chunk {i+1} (Score: {score:.3f}).\") # Verbose\n",
    "                except Exception as e: print(f\"QA Error q='{q}', chunk={i+1}: {e}\")\n",
    "                time.sleep(0.01) \n",
    "    final_extracted = defaultdict(lambda: None)\n",
    "    print(\"\\n--- Aggregated Best Answers --- \"); found_count = 0\n",
    "    for key, res_data in agg_res.items():\n",
    "        if res_data['answer'] is not None: final_extracted[key] = res_data['answer'] ; found_count +=1; print(f\"  - {key}: {'(text)' if 'text' in key and len(str(res_data['answer']))>50 else res_data['answer']} (Best Score: {res_data['score']:.3f})\")\n",
    "    print(\"--- End Aggregation ---\")\n",
    "    print(f\"\\nFull Doc QA Finished. Aggregated {found_count} values.\")\n",
    "    status_widget.value = \"<span style='color: green;'>Status: Full Doc AI QA Complete.</span>\"\n",
    "    return final_extracted, PARSE_STRATEGY_CHUNKED\n",
    "\n",
    "# --- Table Parsing (Placeholders) ---\n",
    "def _extract_tables_pdf(filepath): \n",
    "    if not CAMELOT_AVAILABLE: return [], \"Camelot N/A\"\n",
    "    try: tables = camelot.read_pdf(filepath, pages='all'); print(f\"Camelot Report: {tables.parsing_report}\"); return [tbl.df for tbl in tables], \"OK\"\n",
    "    except Exception as e: return [], f\"Camelot Error: {e}\"\n",
    "def _extract_tables_html(html_content): \n",
    "    try: tables = pd.read_html(io.StringIO(html_content)); print(f\"Pandas found {len(tables)} HTML tables.\"); return tables, \"OK\"\n",
    "    except Exception as e: return [], f\"Pandas HTML Table Error: {e}\"\n",
    "def _parse_tables(tables):\n",
    "    \"\"\"Placeholder: Logic to analyze extracted DataFrames.\"\"\"\n",
    "    print(\"WARN: Table parsing logic is basic placeholder.\"); parsed = defaultdict(lambda: None)\n",
    "    # TODO: Implement robust table identification and data extraction\n",
    "    return parsed\n",
    "\n",
    "# --- Hybrid Parsing (Placeholder) ---\n",
    "def _parse_hybrid(text, tables, status_widget):\n",
    "    \"\"\"Placeholder: Combines QA for text, Regex/Table for numbers.\"\"\"\n",
    "    print(\"WARN: Hybrid parsing logic is basic placeholder.\"); status_widget.value = \"<span style='color: orange;'>Status: Hybrid (Experimental)...</span>\"\n",
    "    extracted_qual = {}; extracted_num_regex = {}; extracted_num_table = {}\n",
    "    # TODO: Implement hybrid logic\n",
    "    final = defaultdict(lambda: None); \n",
    "    status_widget.value = \"<span style='color: green;'>Status: Hybrid Parse Attempt Done.</span>\"\n",
    "    return final, PARSE_STRATEGY_HYBRID\n",
    "\n",
    "# --- NER/RE Placeholder ---\n",
    "def _parse_ner_re(text, status_widget): \n",
    "    print(\"WARN: NER/RE parsing not implemented.\"); status_widget.value = \"<span style='color: orange;'>Status: NER/RE N/A.</span>\"\n",
    "    return defaultdict(lambda: None), PARSE_STRATEGY_NER\n",
    "\n",
    "print(\"-\" * 20, \"Cell 3: Parsing Strategy Helpers Defined\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 4: Helper Functions - Estimation & AI Analysis --%%\n",
    "\n",
    "def _perform_estimations(data_dict):\n",
    "    \"\"\"Attempts to estimate key metrics if components are available.\"\"\"\n",
    "    final = dict(data_dict); log = []; est_done = False\n",
    "    print(\"Attempting estimations...\") \n",
    "    def _valid(*a): return all(isinstance(x,(int,float)) and x is not None and not math.isnan(x) for x in a)\n",
    "    \n",
    "    # Est EBITDA(C)\n",
    "    if final.get('ebitda_current') is None:\n",
    "        opinc, da, rev, cogs, opex = (final.get(k) for k in ['op_income_current', 'da_current', 'revenue_current', 'cogs_current', 'opex_current'])\n",
    "        if _valid(opinc, da): \n",
    "            est = opinc + da; final['ebitda_current'] = est; log.append(f\"Est. EBITDA(C)=OpInc({opinc:.1f})+D&A({da:.1f})={est:.1f}\"); est_done=True\n",
    "        elif _valid(rev, cogs, opex): \n",
    "            base = rev - cogs - opex; da_val = da if _valid(da) else 0; est = base + da_val; final['ebitda_current'] = est; log.append(f\"Est. EBITDA(C)=Rev-Exp+(D&A:{da_val:.1f})={est:.1f}\"); est_done=True\n",
    "            \n",
    "    # Est EBITDA(P) \n",
    "    if final.get('ebitda_prior') is None:\n",
    "         opinc_p, da_p = (final.get(k) for k in ['op_income_prior', 'da_prior'])\n",
    "         if _valid(opinc_p, da_p): \n",
    "             est = opinc_p + da_p; final['ebitda_prior'] = est; log.append(f\"Est. EBITDA(P)=OpInc_p({opinc_p:.1f})+D&A_p({da_p:.1f})={est:.1f}\"); est_done=True\n",
    "             \n",
    "    # Est FCF(C) \n",
    "    if final.get('fcf_current') is None:\n",
    "         ocf, capex = (final.get(k) for k in ['ocf_current', 'capex_current'])\n",
    "         if _valid(ocf, capex): \n",
    "              est = ocf - abs(capex); final['fcf_current'] = est; log.append(f\"Est. FCF(C)=OCF({ocf:.1f})-Capex({abs(capex):.1f})={est:.1f}\"); est_done=True\n",
    "              \n",
    "    # Est FCF(P) \n",
    "    if final.get('fcf_prior') is None:\n",
    "         ocf_p, capex_p = (final.get(k) for k in ['ocf_prior', 'capex_prior'])\n",
    "         if _valid(ocf_p, capex_p): \n",
    "              est = ocf_p - abs(capex_p); final['fcf_prior'] = est; log.append(f\"Est. FCF(P)=OCF_p({ocf_p:.1f})-Capex_p({abs(capex_p):.1f})={est:.1f}\"); est_done=True\n",
    "              \n",
    "    # Est Lev(C) \n",
    "    if final.get('leverage_current') is None:\n",
    "        debt, ebitda = (final.get(k) for k in ['debt_total_current', 'ebitda_current']) \n",
    "        if _valid(debt, ebitda) and abs(ebitda or 0) > 1e-6: \n",
    "            est = debt / ebitda \n",
    "            if 0 < est < 25: # Sanity check\n",
    "                final['leverage_current'] = est\n",
    "                log.append(f\"Est. Lev(C)=Debt({debt:.1f})/EBITDA({ebitda:.1f})={est:.1f}x\") \n",
    "                est_done = True\n",
    "            else: \n",
    "                log.append(f\"Est. Lev(C) skipped (ratio {est:.1f}x unreal.)\")\n",
    "                \n",
    "    # Log estimation results\n",
    "    if est_done: print(\"\\n--- Estimations Performed ---\"); [print(f\"- {l}\") for l in log]; print(\"---\")\n",
    "    else: print(\"\\nNo estimations performed.\")\n",
    "    return final, log # Return final data and log\n",
    "\n",
    "# --- AI Text Analysis Function ---\n",
    "# (Include analyze_drivers_transformer function from previous version)\n",
    "def analyze_drivers_transformer(text, status_widget):\n",
    "    \"\"\"Analyzes driver text using AI pipelines.\"\"\"\n",
    "    req_pipes = [\"summarizer\", \"zero_shot\", \"sentiment\"]; \n",
    "    # Use app_state.pipelines instead of global pipelines\n",
    "    if not all(app_state.pipelines.get(p) for p in req_pipes): return \"<i>(AI analysis models not loaded)</i>\"\n",
    "    if not text or text.strip().lower() == 'n/a': return \"<i>(No text)</i>\"\n",
    "    analysis = {}; status_widget.value = \"<span style='color: blue;'>Status: Analyzing text...</span>\"\n",
    "    try: # Wrap entire analysis in try/except\n",
    "        # Summarization\n",
    "        try: analysis[\"Summary\"] = f\"<i>{html.escape(app_state.pipelines['summarizer'](text, max_length=80, min_length=15, do_sample=False)[0]['summary_text'])}</i>\"\n",
    "        except Exception as e: print(f\"Summary fail: {e}\"); analysis[\"Summary\"] = \"<i>Error</i>\"\n",
    "        # Zero-Shot\n",
    "        try:\n",
    "            text_trunc = text[:TEXT_ANALYSIS_MAX_CHARS_ZS] if len(text) > TEXT_ANALYSIS_MAX_CHARS_ZS else text\n",
    "            if not text_trunc.strip(): raise ValueError(\"Empty ZS text\")\n",
    "            results = app_state.pipelines['zero_shot'](text_trunc, candidate_labels=ZERO_SHOT_LABELS, multi_label=True); \n",
    "            themes = sorted([(l, s) for l, s in zip(results['labels'], results['scores']) if s > ZERO_SHOT_CONFIDENCE_THRESHOLD], key=lambda i: i[1], reverse=True)\n",
    "            analysis[\"Themes\"] = html.escape(\", \".join([f\"{l} ({s:.0%})\" for l, s in themes])) if themes else \"<i>None detected</i>\"\n",
    "        except Exception as e: print(f\"Zero-shot fail: {e}\"); analysis[\"Themes\"] = \"<i>Error</i>\"\n",
    "        # Sentiment\n",
    "        try:\n",
    "            chunks = [text[i:i+TEXT_ANALYSIS_MAX_CHARS_SENTIMENT] for i in range(0, len(text), TEXT_ANALYSIS_MAX_CHARS_SENTIMENT)]; sentiments = []; scores = []\n",
    "            for chunk in chunks:\n",
    "                 if not chunk.strip(): continue \n",
    "                 res = app_state.pipelines['sentiment'](chunk)[0]; sentiments.append(res['label']); scores.append(res['score']) \n",
    "            if sentiments: sentiment = max(set(sentiments), key=sentiments.count); avg_score = sum(s for s, lab in zip(scores, sentiments) if lab == sentiment) / sentiments.count(sentiment); analysis[\"Sentiment\"] = f\"{html.escape(sentiment.capitalize())} ({avg_score:.1%})\" \n",
    "            else: analysis[\"Sentiment\"] = \"<i>N/A</i>\"\n",
    "        except Exception as e: print(f\"Sentiment fail: {e}\"); analysis[\"Sentiment\"] = \"<i>Error</i>\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during text analysis: {e}\")\n",
    "        return \"<i>(Error during AI text analysis)</i>\"\n",
    "    # Format\n",
    "    out = \"<ul style='margin:0; padding-left:20px; font-size:0.9em;'>\"; \n",
    "    if \"Summary\" in analysis: out += f\"<li><b>Summary:</b> {analysis['Summary']}</li>\"\n",
    "    if \"Themes\" in analysis: out += f\"<li><b>Themes:</b> {analysis['Themes']}</li>\"\n",
    "    if \"Sentiment\" in analysis: out += f\"<li><b>Sentiment:</b> {analysis['Sentiment']}</li></ul>\"\n",
    "    return out if analysis else \"<i>(Analysis failed)</i>\"\n",
    "\n",
    "# --- Advanced Analysis Placeholders ---\n",
    "def _link_drivers_to_metrics(data_dict):\n",
    "     \"\"\"Placeholder: Advanced NLP to link qualitative sentences to metric changes.\"\"\"\n",
    "     print(\"WARN: Driver linking not implemented.\"); return {}\n",
    "\n",
    "def _perform_consistency_checks(data_dict):\n",
    "     \"\"\"Placeholder: Check consistency between text/table/estimates.\"\"\"\n",
    "     print(\"WARN: Consistency checks not implemented.\"); return []\n",
    "\n",
    "print(\"-\" * 20, \"Cell 4: Estimation & Analysis Helpers Defined\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 5: Helper Functions - Report Generation & Visualization --%%\n",
    "\n",
    "def _generate_report_html(data_dict, qual_analysis_results, analysis_method):\n",
    "    \"\"\"Generates the final HTML report string using verified/final data.\"\"\"\n",
    "    print(\"Generating HTML report...\")\n",
    "    # Get values safely from data_dict (which should hold the verified/final data)\n",
    "    rev_c, rev_p = data_dict.get('revenue_current'), data_dict.get('revenue_prior')\n",
    "    ebitda_c, ebitda_p = data_dict.get('ebitda_current'), data_dict.get('ebitda_prior')\n",
    "    fcf_c, fcf_p = data_dict.get('fcf_current'), data_dict.get('fcf_prior')\n",
    "    lev_c, lev_p = data_dict.get('leverage_current'), data_dict.get('leverage_prior')\n",
    "    # Get QUALITATIVE text directly from data_dict (should be verified text)\n",
    "    qual_in = { \n",
    "        \"Rev\": data_dict.get('revenue_drivers_text', \"N/A\"), \n",
    "        \"EBITDA\": data_dict.get('ebitda_drivers_text', \"N/A\"), \n",
    "        \"FCF\": data_dict.get('fcf_drivers_text', \"N/A\"), \n",
    "        \"Lev\": data_dict.get('leverage_drivers_text', \"N/A\")\n",
    "    }\n",
    "    \n",
    "    # Calculations\n",
    "    try:\n",
    "        def calc_chg(c, p):\n",
    "            if not all(isinstance(x,(int,float)) and x is not None and not math.isnan(x) for x in [c, p]): return None, None\n",
    "            delta = c - p; return (float('inf') if c>1e-9 else (float('-inf') if c<-1e-9 else 0.0)) if abs(p)<1e-9 else (delta/abs(p)*100), delta\n",
    "        rev_pc, _ = calc_chg(rev_c, rev_p); ebitda_pc, _ = calc_chg(ebitda_c, ebitda_p); fcf_pc, _ = calc_chg(fcf_c, fcf_p)\n",
    "        lev_d = (lev_c - lev_p) if all(isinstance(x,(int,float)) and x is not None and not math.isnan(x) for x in [lev_c, lev_p]) else None\n",
    "        margin_c = (ebitda_c / rev_c * 100) if rev_c and abs(rev_c) > 1e-9 and ebitda_c is not None else None\n",
    "        margin_p = (ebitda_p / rev_p * 100) if rev_p and abs(rev_p) > 1e-9 and ebitda_p is not None else None\n",
    "    except Exception as e: return f\"<h2>Report Error</h2><p>Calc error: {e}</p>\"\n",
    "\n",
    "    # HTML Generation\n",
    "    out = f\"<h2>Financial Performance Summary</h2><p style='font-size:0.9em; color:grey;'><i>(Text analysis: {analysis_method})</i></p>\"\n",
    "    def fmt_qual(lbl, k): \n",
    "        txt = qual_in.get(k, \"N/A\"); analysis = qual_analysis_results.get(k, \"\") \n",
    "        block = f\"<div style='margin-left:15px; margin-top:3px; font-size:0.9em; color:#333; border-left: 2px solid #eee; padding-left: 5px;'><b>AI Analysis:</b> {analysis}</div>\" if analysis and \"<i>(\" not in analysis and \"N/A\" not in analysis else (analysis if \"<i>(\" in analysis else \"\") \n",
    "        esc_txt = html.escape(txt) if txt else \"N/A\"; txt_disp = f\"<p style='margin:2px 0; white-space:pre-wrap;'>{esc_txt}</p>\"\n",
    "        return f\"<li><b>{lbl}:</b> {txt_disp}{block}</li>\"\n",
    "\n",
    "    # Revenue\n",
    "    out += \"<h3>Revenue</h3><ul>\"; s1 = \"<li>Data incomplete.</li>\"\n",
    "    if rev_pc is not None: \n",
    "        if abs(rev_p or 0)<1e-9: s1 = f\"<li>Rev: <strong>{format_currency(rev_c)}</strong>.</li>\"\n",
    "        else: d = \"increased\" if rev_pc >= 0 else \"decreased\"; d = \"~flat\" if abs(rev_pc) < 0.05 else d; s1 = f\"<li>Rev {d} <strong>{format_percentage(abs(rev_pc))}</strong> YoY to <strong>{format_currency(rev_c)}</strong> (from {format_currency(rev_p)}).</li>\"\n",
    "    elif rev_c is not None: s1 = f\"<li>Current Rev: <strong>{format_currency(rev_c)}</strong>.</li>\"\n",
    "    out += s1; out += fmt_qual(\"Drivers/Factors\", \"Rev\"); out += \"</ul>\"\n",
    "    # EBITDA\n",
    "    out += \"<h3>EBITDA & Margin</h3><ul>\"; s1 = \"<li>Data incomplete.</li>\"; s2 = \"<li>Margin N/A.</li>\" \n",
    "    if ebitda_pc is not None: \n",
    "        if abs(ebitda_p or 0)<1e-9: s1 = f\"<li>EBITDA: <strong>{format_currency(ebitda_c)}</strong>.</li>\"\n",
    "        else: d = \"increased\" if ebitda_pc >= 0 else \"decreased\"; d = \"~flat\" if abs(ebitda_pc) < 0.05 else d; s1 = f\"<li>EBITDA {d} <strong>{format_percentage(abs(ebitda_pc))}</strong> YoY to <strong>{format_currency(ebitda_c)}</strong> (from {format_currency(ebitda_p)}).</li>\"\n",
    "        if margin_c is not None and margin_p is not None: margin_d = margin_c - margin_p; bps = margin_d * 100; s2 = f\"<li>Margin stable ~{format_percentage(margin_c)}.</li>\" if abs(margin_d)<0.05 else f\"<li>Margin {'expanded' if margin_d>0 else 'contracted'} {abs(bps):.0f} bps YoY to <strong>{format_percentage(margin_c)}</strong>.</li>\"\n",
    "        elif margin_c is not None: s2 = f\"<li>Current margin: {format_percentage(margin_c)}.</li>\"\n",
    "    elif ebitda_c is not None: s1 = f\"<li>Current EBITDA: <strong>{format_currency(ebitda_c)}</strong>.</li>\"; if margin_c is not None: s2 = f\"<li>Current margin: {format_percentage(margin_c)}.</li>\"\n",
    "    out += s1; out += s2; out += fmt_qual(\"Drivers/Factors\", \"EBITDA\"); out += \"</ul>\"\n",
    "    # FCF\n",
    "    out += \"<h3>Free Cash Flow</h3><ul>\"; s1 = \"<li>Data incomplete.</li>\"\n",
    "    if fcf_pc is not None and fcf_c is not None and fcf_p is not None: \n",
    "        neg_p=fcf_p<-1e-9; neg_c=fcf_c<-1e-9; zero_p=abs(fcf_p)<1e-9\n",
    "        if neg_p and not neg_c: s1 = f\"<li>FCF improved to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>\"\n",
    "        elif not neg_p and neg_c: s1 = f\"<li>FCF declined to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>\"\n",
    "        elif zero_p: s1 = f\"<li>FCF: <strong>{format_currency(fcf_c)}</strong>.</li>\"\n",
    "        elif neg_p and neg_c: d=\"improved\" if fcf_c>fcf_p else \"worsened\"; s1 = f\"<li>FCF {d} to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>\"\n",
    "        else: d=\"increased\" if fcf_pc >= 0 else \"decreased\"; d=\"~flat\" if abs(fcf_pc)<0.05 else d; s1 = f\"<li>FCF {d} <strong>{format_percentage(abs(fcf_pc))}</strong> YoY to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>\"\n",
    "    elif fcf_c is not None: s1 = f\"<li>Current FCF: <strong>{format_currency(fcf_c)}</strong>.</li>\"\n",
    "    out += s1; out += fmt_qual(\"Drivers/Factors\", \"FCF\"); out += \"</ul>\"\n",
    "    # Leverage\n",
    "    out += \"<h3>Leverage</h3><ul>\"; s1 = \"<li>Data incomplete.</li>\"\n",
    "    if lev_d is not None and lev_c is not None and lev_p is not None: \n",
    "        delta=abs(lev_d); s1=f\"<li>Leverage stable ~<strong>{format_leverage(lev_c)}</strong>.</li>\" if delta<0.05 else (f\"<li>Leverage increased {delta:.1f}x YoY to <strong>{format_leverage(lev_c)}</strong>.</li>\" if lev_d>0 else f\"<li>Leverage decreased {delta:.1f}x YoY to <strong>{format_leverage(lev_c)}</strong>.</li>\")\n",
    "    elif lev_c is not None: s1 = f\"<li>Current Leverage: <strong>{format_leverage(lev_c)}</strong>.</li>\"\n",
    "    out += s1; out += fmt_qual(\"Drivers/Factors\", \"Lev\"); out += \"</ul>\"\n",
    "    \n",
    "    # --- Add Visualization --- (Basic Example)\n",
    "    if PLT_AVAILABLE:\n",
    "         out += \"<br><h4>YoY Visualizations (Basic)</h4>\"\n",
    "         out += _generate_yoy_chart(\"Revenue\", rev_c, rev_p)\n",
    "         out += _generate_yoy_chart(\"EBITDA\", ebitda_c, ebitda_p)\n",
    "         # Add more charts as needed\n",
    "         \n",
    "    return out\n",
    "\n",
    "def _generate_report_nlg(data_dict, analysis_results, status_widget):\n",
    "    \"\"\"Placeholder: Use text-generation model for narrative summary.\"\"\"\n",
    "    status_widget.value = \"<span style='color: blue;'>Status: Generating NLG Summary...</span>\"\n",
    "    nlg_pipe = app_state.pipelines.get(\"text-generation\") # Use state\n",
    "    if not nlg_pipe: return \"<h2>NLG Error</h2><p>Text Generation model not loaded. Load one (e.g., 'gpt2') via `load_models`.</p>\"\n",
    "    try:\n",
    "        # Simple prompt construction - needs refinement!\n",
    "        prompt = f\"Summarize financial performance:\\nRevenue: {format_currency(data_dict.get('revenue_current'))} vs {format_currency(data_dict.get('revenue_prior'))}\\nEBITDA: {format_currency(data_dict.get('ebitda_current'))} vs {format_currency(data_dict.get('ebitda_prior'))}\\nFCF: {format_currency(data_dict.get('fcf_current'))} vs {format_currency(data_dict.get('fcf_prior'))}\\nLeverage: {format_leverage(data_dict.get('leverage_current'))} vs {format_leverage(data_dict.get('leverage_prior'))}\\nRevenue Drivers: {analysis_results.get('Rev', '')}\\nEBITDA Drivers: {analysis_results.get('EBITDA', '')}\\nSummary:\"\n",
    "        # Truncate prompt if too long for model\n",
    "        max_prompt_len = 512 # Example limit\n",
    "        truncated_prompt = prompt[:max_prompt_len]\n",
    "        \n",
    "        result = nlg_pipe(truncated_prompt, max_new_tokens=150, num_return_sequences=1, temperature=0.7, do_sample=True) \n",
    "        narrative = result[0]['generated_text'].replace(truncated_prompt, \"\").strip() \n",
    "        status_widget.value = \"<span style='color: green;'>Status: NLG Summary Generated.</span>\"\n",
    "        return f\"<h2>AI Generated Narrative (Experimental)</h2><p>{html.escape(narrative)}</p>\"\n",
    "    except Exception as e: print(f\"NLG Error: {e}\"); status_widget.value = \"<span style='color: red;'>Status: NLG Error.</span>\"; return f\"<h2>NLG Error</h2><p>{e}</p>\"\n",
    "\n",
    "def _generate_yoy_chart(metric_name, current_val, prior_val):\n",
    "     \"\"\"Generates a simple YoY bar chart image as base64 HTML.\"\"\"\n",
    "     # ... (Implementation from previous version) ...\n",
    "     if not PLT_AVAILABLE or not all(isinstance(x,(int,float)) and not math.isnan(x) for x in [current_val, prior_val]): return \"\"\n",
    "     try:\n",
    "         fig, ax = plt.subplots(figsize=(3, 2.5)); labels = ['Prior', 'Current']\n",
    "         values = [prior_val / 1e6 if prior_val else 0, current_val / 1e6 if current_val else 0] # Plot in millions\n",
    "         colors = ['#B0B0B0', '#4682B4'] # Grey, SteelBlue\n",
    "         ax.bar(labels, values, color=colors, width=0.6)\n",
    "         ax.set_ylabel('$ Millions', fontsize=9); ax.set_title(f'{metric_name} YoY', fontsize=10)\n",
    "         ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "         ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False) # Cleaner look\n",
    "         plt.tight_layout(); buf = BytesIO(); plt.savefig(buf, format='png', bbox_inches='tight'); plt.close(fig); buf.seek(0)\n",
    "         img_64 = base64.b64encode(buf.read()).decode('utf-8'); return f'<img src=\"data:image/png;base64,{img_64}\" alt=\"{metric_name} Chart\" style=\"margin: 5px;\"/>'\n",
    "     except Exception as e: print(f\"Chart Error {metric_name}: {e}\"); return \"\"\n",
    "\n",
    "# --- Export Functions ---\n",
    "def _export_report_markdown(html_content):\n",
    "    \"\"\"Basic conversion of HTML report to Markdown (requires html2text).\"\"\"\n",
    "    try: \n",
    "        import html2text\n",
    "        h = html2text.HTML2Text(); h.ignore_links = True; h.ignore_images = True # Configure\n",
    "        md = h.handle(html_content)\n",
    "        md_path = \"financial_report.md\"\n",
    "        with open(md_path, 'w', encoding='utf-8') as f: f.write(md)\n",
    "        return f\"Report saved to {md_path}\"\n",
    "    except ImportError: return \"Markdown export requires `html2text`. Install it (`pip install html2text`).\"\n",
    "    except Exception as e: return f\"Markdown conversion error: {e}\"\n",
    "    \n",
    "def _export_report_pdf(html_content):\n",
    "    \"\"\"Basic PDF export using fpdf2 (very limited HTML support).\"\"\"\n",
    "    if not FPDF_AVAILABLE: return \"FPDF library not installed.\"\n",
    "    try:\n",
    "        pdf = FPDF(); pdf.add_page(); pdf.set_font(\"Arial\", size=10)\n",
    "        # Attempt to write basic HTML (fpdf2 has limited support)\n",
    "        # For better results, convert HTML->MD first, then MD->PDF or use Weasyprint\n",
    "        try: pdf.write_html(html_content) # May fail on complex HTML\n",
    "        except: pdf.multi_cell(0, 5, \"HTML Conversion Failed - Raw Text:\\n\\n\" + BeautifulSoup(html_content, 'html.parser').get_text()) # Fallback\n",
    "        pdf_path = \"financial_report.pdf\"; pdf.output(pdf_path, \"F\")\n",
    "        return f\"Basic PDF report saved to {pdf_path}.\"\n",
    "    except Exception as e: return f\"Error exporting PDF: {e}\"\n",
    "\n",
    "print(\"-\" * 20, \"Cell 5: Report Generation Helpers Defined\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 6: Model Loading Trigger --%%\n",
    "\n",
    "# Provides a button in the notebook output to explicitly load models after setup.\n",
    "load_models_button_cell6 = widgets.Button(description=\"Load AI Models (if not loaded)\", button_style='info', icon='download')\n",
    "load_models_output_cell6 = widgets.Output()\n",
    "\n",
    "def on_load_click_cell6(b):\n",
    "     with load_models_output_cell6:\n",
    "         clear_output(wait=True) # Clear previous load messages\n",
    "         print(\"Model loading requested...\")\n",
    "         load_models(load_status_label) # Call the main loading function, updates global status label\n",
    "\n",
    "load_models_button_cell6.on_click(on_load_click_cell6)\n",
    "\n",
    "# Display the button for this cell's output\n",
    "display(widgets.VBox([load_models_button_cell6, load_models_output_cell6]))\n",
    "\n",
    "print(\"-\" * 20, \"Cell 6: Model Loading Cell Complete (Click button above)\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 7: UI Widget Setup --%%\n",
    "\n",
    "# Define all widgets used in the UI layout\n",
    "print(\"Defining UI widgets...\")\n",
    "\n",
    "# --- Styles & Layouts ---\n",
    "style = {'description_width': 'initial'}; \n",
    "layout_half = widgets.Layout(width='48%') \n",
    "layout_text = widgets.Layout(width='98%', height='100px') \n",
    "\n",
    "# --- Section 1 Widgets: Input & Parsing ---\n",
    "file_upload = widgets.FileUpload(accept='.txt,.pdf,.docx,.html', multiple=False, description=\"Upload Doc\") \n",
    "url_input = widgets.Text(description=\"Or Enter URL:\", placeholder=\"http://...\", layout=widgets.Layout(width='60%'))\n",
    "fetch_url_btn = widgets.Button(description=\"Fetch URL\", icon='download', button_style='info', tooltip=\"Fetch content from URL\")\n",
    "data_source_label = widgets.HTML(value=\"<i>No document loaded yet.</i>\")\n",
    "parse_strategy_selector = widgets.RadioButtons(options=[PARSE_STRATEGY_STANDARD, PARSE_STRATEGY_CHUNKED, PARSE_STRATEGY_HYBRID, PARSE_STRATEGY_TABLE, PARSE_STRATEGY_REGEX, PARSE_STRATEGY_NER], value=DEFAULT_PARSE_STRATEGY, description='Parsing Strategy:', style=style, layout=widgets.Layout(width='max-content'))\n",
    "parse_btn = widgets.Button(description=\"Parse Document\", button_style='info', icon='cogs', tooltip=\"Extract data using selected strategy\")\n",
    "parse_out = widgets.Output() # Output for parsing status messages\n",
    "custom_q_in = widgets.Text(description=\"Follow-up Q:\", placeholder=\"Ask AI about the loaded text...\", layout=widgets.Layout(width='70%'), style=style)\n",
    "custom_q_btn = widgets.Button(description=\"Ask\", button_style='primary', tooltip=\"Run custom question\")\n",
    "# ***** Definition for custom_qa_output *****\n",
    "custom_q_out = widgets.Output() # Output for custom QA results\n",
    "# custom_qa_status_label defined globally in Cell 1\n",
    "\n",
    "# --- Section 2 Widgets: Data Input/Verification ---\n",
    "rev_c_in = widgets.FloatText(description=\"Rev (C, $mm):\", style=style, layout=layout_half)\n",
    "rev_p_in = widgets.FloatText(description=\"Rev (P, $mm):\", style=style, layout=layout_half)\n",
    "rev_drv_in = widgets.Textarea(description=\"Rev Drivers/Notes:\", placeholder=\"(Auto-populated/Manual)\", style=style, layout=layout_text)\n",
    "ebitda_c_in = widgets.FloatText(description=\"EBITDA (C, $mm):\", style=style, layout=layout_half)\n",
    "ebitda_p_in = widgets.FloatText(description=\"EBITDA (P, $mm):\", style=style, layout=layout_half)\n",
    "ebitda_drv_in = widgets.Textarea(description=\"EBITDA Drivers/Notes:\", placeholder=\"(Auto/Manual)\", style=style, layout=layout_text)\n",
    "fcf_c_in = widgets.FloatText(description=\"FCF (C, $mm):\", style=style, layout=layout_half)\n",
    "fcf_p_in = widgets.FloatText(description=\"FCF (P, $mm):\", style=style, layout=layout_half)\n",
    "fcf_drv_in = widgets.Textarea(description=\"FCF Drivers/Notes:\", placeholder=\"(Auto/Manual)\", style=style, layout=layout_text)\n",
    "lev_c_in = widgets.FloatText(description=\"Leverage (C, x):\", style=style, layout=layout_half)\n",
    "lev_p_in = widgets.FloatText(description=\"Leverage (P, x):\", style=style, layout=layout_half)\n",
    "lev_drv_in = widgets.Textarea(description=\"Leverage Drivers/Notes:\", placeholder=\"(Auto/Manual)\", style=style, layout=layout_text)\n",
    "benchmark_input_area = widgets.Textarea(description=\"Benchmark Data (Optional):\", placeholder=\"Enter industry or historical data...\", layout=widgets.Layout(width='98%', height='60px'), style=style)\n",
    "\n",
    "# --- Section 3 Widgets: Report Generation & Export ---\n",
    "gen_report_btn = widgets.Button(description=\"Generate Report\", button_style='success', icon='file-text', tooltip=\"Generate analysis report\") # Updated icon\n",
    "nlg_report_btn = widgets.Button(description=\"Generate NLG Summary (Experimental)\", icon='magic', tooltip=\"Use AI to generate narrative text\")\n",
    "export_md_btn = widgets.Button(description=\"Export MD\", icon='file-code', tooltip=\"Export report as Markdown\") # Updated icon\n",
    "export_pdf_btn = widgets.Button(description=\"Export PDF\", icon='file-pdf', tooltip=\"Export basic PDF report\") # Updated icon\n",
    "report_out = widgets.Output() # Output area for the final report & export messages\n",
    "\n",
    "print(\"-\" * 20, \"Cell 7: UI Widgets Defined\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 8: UI Event Handlers --%%\n",
    "\n",
    "# --- Input Handlers ---\n",
    "def on_upload_change(change):\n",
    "    \"\"\"Handles file upload, extracts text and potentially tables.\"\"\"\n",
    "    # ... (Implementation from previous version - using app_state) ...\n",
    "    if not change['new']: return \n",
    "    uploaded_file = change['new'][0] \n",
    "    filename = uploaded_file['name']; content = uploaded_file['content'] \n",
    "    print(f\"Processing uploaded file: {filename} ({len(content)} bytes)\")\n",
    "    data_source_label.value = f\"<i>Processing: {filename}</i>\"\n",
    "    app_state.document_name = filename; app_state.document_text = None; app_state.document_tables = []\n",
    "    text = f\"Error processing file: {filename}\"; tables = []\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(content)\n",
    "        temp_pdf_path = \"temp_uploaded_file.pdf\" \n",
    "        try:\n",
    "            with open(temp_pdf_path, 'wb') as f: f.write(content)\n",
    "            tables, msg = _extract_tables_pdf(temp_pdf_path); print(msg); app_state.document_tables = tables\n",
    "        except Exception as e: print(f\"PDF Table extraction failed: {e}\")\n",
    "        finally: \n",
    "             if os.path.exists(temp_pdf_path): os.remove(temp_pdf_path)\n",
    "    elif filename.lower().endswith('.docx'): text = extract_text_from_docx(content)\n",
    "    elif filename.lower().endswith(('.html', '.htm')):\n",
    "        html_str = extract_text_from_txt(content) \n",
    "        if not html_str.startswith(\"Error:\"): \n",
    "             try: text = BeautifulSoup(html_str, 'html.parser').get_text(separator='\\n', strip=True)\n",
    "             except Exception as e: text = f\"HTML text parse error: {e}\"\n",
    "             tables, msg = _extract_tables_html(html_str); print(msg); app_state.document_tables = tables\n",
    "        else: text = html_str\n",
    "    elif filename.lower().endswith('.txt'): text = extract_text_from_txt(content)\n",
    "    else: text = f\"Error: Unsupported file type '{filename}'.\"\n",
    "    app_state.document_text = text; pr_input.value = text[:20000] # Update preview\n",
    "    data_source_label.value = f\"<i>Loaded: {filename} ({len(text)} chars, {len(tables)} tables)</i>\"\n",
    "    parse_status_label.value = \"Status: Ready to parse.\"; clear_output(wait=True)\n",
    "\n",
    "def on_fetch_url_click(b):\n",
    "    \"\"\"Handles fetching and processing a URL.\"\"\"\n",
    "    # ... (Implementation from previous version - using app_state) ...\n",
    "    url = url_input.value\n",
    "    if not url or not url.startswith(('http://', 'https://')): data_source_label.value = \"<i>Error: Invalid URL.</i>\"; return\n",
    "    print(f\"Fetching URL: {url}\"); data_source_label.value = f\"<i>Fetching...</i>\"\n",
    "    app_state.document_name = url; app_state.document_text = None; app_state.document_tables = []\n",
    "    html_content = \"\"; text = \"Error fetching/parsing URL.\"\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=headers, timeout=15); response.raise_for_status()\n",
    "        html_content = response.text \n",
    "        if HTML_AVAILABLE and html_content:\n",
    "            try: soup = BeautifulSoup(html_content, 'html.parser'); [s.decompose() for s in soup([\"script\", \"style\"])]; text = soup.get_text(separator='\\n', strip=True)\n",
    "            except Exception as e: text = f\"HTML text parse error: {e}\"\n",
    "    except Exception as e: text = f\"Error fetching URL: {e}\"; print(text)\n",
    "    tables = []\n",
    "    if html_content: tables, msg = _extract_tables_html(html_content); print(msg); app_state.document_tables = tables\n",
    "    app_state.document_text = text; pr_input.value = text[:20000] \n",
    "    data_source_label.value = f\"<i>Loaded: {url} ({len(text)} chars, {len(tables)} tables)</i>\"\n",
    "    parse_status_label.value = \"Status: Ready to parse.\"; clear_output(wait=True)\n",
    "\n",
    "# --- Parsing Handler ---\n",
    "def on_parse_button_click(b):\n",
    "    \"\"\"Handles 'Parse Document' button using selected strategy.\"\"\"\n",
    "    # ... (Implementation from previous version - using app_state) ...\n",
    "    parse_out.clear_output(wait=True); analysis_out.clear_output() \n",
    "    app_state.parsed_data = defaultdict(lambda: None); app_state.estimation_log = []\n",
    "    with parse_out: \n",
    "        parse_strategy = parse_strategy_selector.value \n",
    "        parse_status_label.value = f\"<span style='color: blue;'>Status: Parsing ({parse_strategy})...</span>\"; print(f\"Initiating parse: {parse_strategy}\")\n",
    "        doc_text = app_state.get(\"document_text\"); doc_tables = app_state.get(\"document_tables\", [])\n",
    "        if not doc_text or not doc_text.strip(): print(\"Error: No text loaded.\"); parse_status_label.value = \"<span style='color: red;'>Status: Error - No text.</span>\"; return\n",
    "        extracted = defaultdict(lambda: None); method = \"Unknown\"; success = False \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            if parse_strategy == PARSE_STRATEGY_STANDARD:\n",
    "                if not (TRANSFORMERS_AVAILABLE and app_state.models_loaded and app_state.pipelines.get(\"qa\")): raise RuntimeError(\"Standard AI QA requires loaded QA model.\")\n",
    "                extracted, method = _parse_standard_qa(doc_text, parse_status_label)\n",
    "            elif parse_strategy == PARSE_STRATEGY_CHUNKED:\n",
    "                if not (TRANSFORMERS_AVAILABLE and app_state.models_loaded and app_state.pipelines.get(\"qa\")): raise RuntimeError(\"Full Document AI QA requires loaded QA model.\")\n",
    "                extracted, method = _parse_chunked_qa(doc_text, parse_status_label)\n",
    "            elif parse_strategy == PARSE_STRATEGY_REGEX:\n",
    "                 extracted, method = _parse_regex_only(doc_text, parse_status_label)\n",
    "            elif parse_strategy == PARSE_STRATEGY_TABLE:\n",
    "                 table_data = _parse_tables(doc_tables); regex_data, _ = _parse_regex_only(doc_text, parse_status_label)\n",
    "                 extracted.update(regex_data); extracted.update(table_data); method = PARSE_STRATEGY_TABLE; print(\"Table Extraction Finished (Basic).\")\n",
    "            elif parse_strategy == PARSE_STRATEGY_HYBRID:\n",
    "                 if not (TRANSFORMERS_AVAILABLE and app_state.models_loaded and app_state.pipelines.get(\"qa\")): raise RuntimeError(\"Hybrid parsing requires loaded QA model.\")\n",
    "                 extracted, method = _parse_hybrid(doc_text, doc_tables, parse_status_label)\n",
    "            elif parse_strategy == PARSE_STRATEGY_NER:\n",
    "                 extracted, method = _parse_ner_re(doc_text, parse_status_label) \n",
    "            else: raise ValueError(f\"Unknown strategy: {parse_strategy}\")\n",
    "            success = True; print(f\"Parsing strategy '{method}' completed in {time.time() - start_time:.1f}s.\")\n",
    "        except Exception as e: print(f\"ERROR during parsing '{parse_strategy}': {e}\"); parse_status_label.value = f\"<span style='color: red;'>Status: Error during parsing.</span>\"; success = False; method = f\"Failed ({parse_strategy})\"\n",
    "        \n",
    "        final_data, estimation_log = _perform_estimations(extracted) if success else (extracted, [])\n",
    "        app_state.parsed_data = final_data; app_state.estimation_log = estimation_log\n",
    "            \n",
    "        if success: \n",
    "            w_map = {'revenue_current': rev_c_in, 'revenue_prior': rev_p_in, 'ebitda_current': ebitda_c_in, 'ebitda_prior': ebitda_p_in, 'fcf_current': fcf_c_in, 'fcf_prior': fcf_p_in, 'leverage_current': lev_c_in, 'leverage_prior': lev_p_in, 'revenue_drivers_text': rev_drv_in, 'ebitda_drivers_text': ebitda_drv_in, 'fcf_drivers_text': fcf_drv_in, 'leverage_drivers_text': lev_drv_in}\n",
    "            print(\"\\nPopulating UI:\"); pop_count = 0\n",
    "            for k, w in w_map.items():\n",
    "                val = final.get(k); est = any(k.split('_')[0].lower() in l.lower() for l in estimation_log if k.lower() in l.lower()) \n",
    "                if val is not None:\n",
    "                    try: w.value = float(f\"{val:.2f}\") if isinstance(w, widgets.FloatText) and isinstance(val, float) else val; pop_count += 1; print(f\"  - Set {k}{' (Est.)' if est else ''}: {'(text)' if isinstance(val, str) and len(val)>50 else val}\")\n",
    "                    except: w.value = None \n",
    "            print(f\"\\nPopulated {pop_count} fields. Method: {method}\"); print(\"\\n>>> !! CRITICAL: Review ALL fields. Edit as needed. !! <<<\")\n",
    "            parse_status_label.value = f\"<span style='color: green;'>Status: Parse OK ({method}). VERIFY VALUES.</span>\"\n",
    "        elif success: parse_status_label.value = f\"<span style='color: orange;'>Status: Parsed ({method}), no data.</span>\"\n",
    "        analysis_status_label.value = \"Status: Ready.\"\n",
    "\n",
    "# --- Interactive QA Handler ---\n",
    "def on_custom_qa_click(b):\n",
    "    \"\"\"Handles 'Ask AI' button for interactive QA.\"\"\"\n",
    "    # ... (Implementation from previous version - uses app_state) ...\n",
    "    custom_q_out.clear_output(wait=True) \n",
    "    custom_qa_status_label.value = \"<span style='color: blue;'>Processing...</span>\"\n",
    "    with custom_q_out: \n",
    "        q = custom_q_in.value; txt = app_state.document_text; qa_pipe = app_state.pipelines.get(\"qa\")\n",
    "        if not q or not q.strip(): print(\"ERROR: Enter question.\"); custom_qa_status_label.value = \"<span style='color: red;'>Status: Enter question.</span>\"; return\n",
    "        if not txt or not txt.strip(): print(\"ERROR: No document loaded.\"); custom_qa_status_label.value = \"<span style='color: red;'>Status: Load document first.</span>\"; return\n",
    "        if not qa_pipe: print(\"ERROR: QA model not loaded.\"); custom_qa_status_label.value = \"<span style='color: red;'>Status: Load QA model.</span>\"; return\n",
    "        print(f\"Asking AI: '{html.escape(q)}'\"); \n",
    "        try:\n",
    "            res = qa_pipe(question=q, context=txt, handle_impossible_answer=True)\n",
    "            ans, score = res.get('answer'), res.get('score', 0)\n",
    "            print(f\"\\nAnswer: {html.escape(ans if ans else '(No answer found)')}\")\n",
    "            print(f\"Confidence: {score:.3f}\")\n",
    "            if not ans or score < QA_SCORE_THRESHOLD: print(\"(Low confidence or no answer found)\")\n",
    "            custom_qa_status_label.value = f\"<span style='color: {'green' if ans and score >= QA_SCORE_THRESHOLD else 'orange'};'>Status: Custom QA complete.</span>\"\n",
    "        except Exception as e: print(f\"\\nERROR: {e}\"); custom_qa_status_label.value = \"<span style='color: red;'>Status: Custom QA Error.</span>\"\n",
    "\n",
    "# --- Report Generation Handler ---\n",
    "def on_generate_click(b):\n",
    "    \"\"\"Handles 'Generate Report' button.\"\"\"\n",
    "    # ... (Implementation from previous version - uses app_state) ...\n",
    "    report_out.clear_output(wait=True) \n",
    "    with report_out: \n",
    "        analysis_status_label.value = \"<span style='color: blue;'>Status: Generating...</span>\"; print(\"Generating Report...\")\n",
    "        # Get verified data from UI widgets directly for final report\n",
    "        verified_data = defaultdict(lambda: None)\n",
    "        try:\n",
    "            def get_units(w): v=w.value; return v * 1e6 if isinstance(v,(int,float)) and v is not None and not math.isnan(v) else None\n",
    "            verified_data['revenue_current'] = get_units(rev_c_in); verified_data['revenue_prior'] = get_units(rev_p_in)\n",
    "            verified_data['ebitda_current'] = get_units(ebitda_c_in); verified_data['ebitda_prior'] = get_units(ebitda_p_in)\n",
    "            verified_data['fcf_current'] = get_units(fcf_c_in); verified_data['fcf_prior'] = get_units(fcf_p_in)\n",
    "            verified_data['leverage_current'] = lev_c_in.value if isinstance(lev_c_in.value,(int,float)) else None\n",
    "            verified_data['leverage_prior'] = lev_p_in.value if isinstance(lev_p_in.value,(int,float)) else None\n",
    "            verified_data['revenue_drivers_text'] = rev_drv_in.value or \"N/A\"; verified_data['ebitda_drivers_text'] = ebitda_drv_in.value or \"N/A\"\n",
    "            verified_data['fcf_drivers_text'] = fcf_drv_in.value or \"N/A\"; verified_data['leverage_drivers_text'] = lev_drv_in.value or \"N/A\"\n",
    "        except Exception as e: print(f\"Input Error: {e}\"); analysis_status_label.value = f\"<span style='color: red;'>Status: Input Error</span>\"; return\n",
    "        \n",
    "        # Run AI Text Analysis\n",
    "        analysis_status_label.value = \"<span style='color: blue;'>Status: Analyzing text...</span>\"; \n",
    "        qual_an_res = {}; method = \"Basic Fallback\" \n",
    "        analysis_ok = TRANSFORMERS_AVAILABLE and app_state.models_loaded and all(app_state.pipelines.get(k) for k in [\"summarizer\", \"zero_shot\", \"sentiment\"])\n",
    "        qual_map = {\"Rev\": \"revenue_drivers_text\", \"EBITDA\": \"ebitda_drivers_text\", \"FCF\": \"fcf_drivers_text\", \"Lev\": \"leverage_drivers_text\"}\n",
    "        if analysis_ok:\n",
    "            print(\"Attempting AI analysis...\"); method = \"Transformer (AI)\"\n",
    "            for report_key, data_key in qual_map.items():\n",
    "                txt = verified_data.get(data_key, \"N/A\")\n",
    "                analysis_status_label.value = f\"<span style='color: blue;'>Status: Analyzing '{report_key}'...</span>\"\n",
    "                try: qual_an_res[report_key] = analyze_drivers_transformer(txt, analysis_status_label) \n",
    "                except Exception as e: print(f\"AI analysis fail {report_key}: {e}\"); qual_an_res[report_key] = analyze_drivers_fallback(txt); method = \"Mixed\"\n",
    "        else:\n",
    "             reason = \"(Lib N/A)\" if not TRANSFORMERS_AVAILABLE else \"(Models not loaded)\"; print(f\"Using basic analysis {reason}.\"); analysis_status_label.value = f\"<span style='color: orange;'>Status: Basic analysis {reason}...</span>\"\n",
    "             for report_key, data_key in qual_map.items(): qual_an_res[report_key] = analyze_drivers_fallback(verified_data.get(data_key, \"N/A\"))\n",
    "        analysis_status_label.value = f\"<span style='color: blue;'>Status: Text analysis done ({method}).</span>\"\n",
    "        app_state.analysis_results = qual_an_res # Store results\n",
    "\n",
    "        # Generate HTML Report\n",
    "        analysis_status_label.value = \"<span style='color: blue;'>Status: Generating HTML...</span>\"\n",
    "        report_html = _generate_report_html(verified_data, qual_an_res, method)\n",
    "        app_state.current_report_html = report_html \n",
    "        \n",
    "        # Display Report\n",
    "        clear_output(wait=True); display(HTML(report_html)); \n",
    "        analysis_status_label.value = \"<span style='color: green;'>Status: Report Generated.</span>\"; print(\"\\nReport finished.\") \n",
    "\n",
    "# --- Optional: NLG Handler ---\n",
    "def on_nlg_click(b):\n",
    "     report_out.clear_output(wait=True)\n",
    "     with report_out:\n",
    "         if not (TRANSFORMERS_AVAILABLE and app_state.models_loaded and app_state.pipelines.get(\"text-generation\")): \n",
    "              print(\"NLG requires text-generation model (e.g., 'gpt2'). Load it via `load_models` if needed.\"); return\n",
    "         print(\"Generating NLG Summary (Experimental)...\")\n",
    "         # Get data from UI widgets for NLG prompt\n",
    "         verified_data = { # Re-read UI data for NLG\n",
    "             'revenue_current': rev_c_in.value, 'revenue_prior': rev_p_in.value, \n",
    "             'ebitda_current': ebitda_c_in.value, 'ebitda_prior': ebitda_p_in.value,\n",
    "             'fcf_current': fcf_c_in.value, 'fcf_prior': fcf_p_in.value,\n",
    "             'leverage_current': lev_c_in.value, 'leverage_prior': lev_p_in.value\n",
    "         }\n",
    "         narrative_html = _generate_report_nlg(verified_data, app_state.analysis_results, analysis_status_label)\n",
    "         display(HTML(app_state.current_report_html + \"<hr>\" + narrative_html)) # Show below main report\n",
    "\n",
    "# --- Optional: Export Handlers ---\n",
    "def on_export_md_click(b):\n",
    "     report_out.clear_output(wait=True)\n",
    "     with report_out:\n",
    "          html_content = app_state.current_report_html\n",
    "          if not html_content: print(\"Generate report first.\"); return\n",
    "          md_content = _export_report_markdown(html_content) \n",
    "          print(\"--- Markdown Output (Basic) ---\")\n",
    "          print(md_content)\n",
    "          # Consider adding download link here\n",
    "          \n",
    "def on_export_pdf_click(b):\n",
    "     report_out.clear_output(wait=True)\n",
    "     with report_out:\n",
    "          html_content = app_state.current_report_html\n",
    "          if not html_content: print(\"Generate report first.\"); return\n",
    "          pdf_message = _export_report_pdf(html_content) \n",
    "          print(pdf_message)\n",
    "\n",
    "print(\"-\" * 20, \"Cell 8: Event Handlers Defined\", \"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%-- Cell 9: UI Layout & Display --%%\n",
    "\n",
    "print(\"Assembling UI Layout...\")\n",
    "\n",
    "# --- UI Layout Construction ---\n",
    "# Section for Model Loading Controls\n",
    "model_load_section = widgets.VBox([\n",
    "    widgets.HTML(\"<b>AI Model Control:</b>\"), \n",
    "    widgets.HBox([load_btn, load_status_label]) # Use load_btn defined in Cell 7\n",
    "])\n",
    "\n",
    "# Section 1 Layout: Parsing & Interactive QA\n",
    "pr_section = widgets.VBox([\n",
    "    widgets.HTML(\"<b>1. Load Document</b>\"),\n",
    "    widgets.HBox([file_upload, url_input, fetch_url_btn]), \n",
    "    data_source_label, \n",
    "    widgets.HTML(\"<hr style='margin: 10px 0;'><b>2. Select Parsing Strategy & Parse</b>\"), \n",
    "    parse_strategy_selector, \n",
    "    parse_btn, \n",
    "    parse_status_label, \n",
    "    parse_out, \n",
    "    # Interactive QA Sub-section\n",
    "    widgets.HTML(\"<hr style='margin: 10px 0;'><b>3. Interactive Follow-up QA (Optional)</b>\"), \n",
    "    widgets.HTML(\"<p style='font-size:0.9em;'>Ask specific questions about the loaded text (AI models must be loaded).</p>\"),\n",
    "    widgets.HBox([custom_q_in, custom_q_btn]), \n",
    "    custom_qa_status_label, \n",
    "    custom_q_out \n",
    "])\n",
    "\n",
    "# Section 2 Layout: Data Input/Verification\n",
    "manual_section = widgets.VBox([\n",
    "     widgets.HTML(\"<b>Review / Enter Financial Data:</b><p style='font-size:0.9em'>(Populated by parsing - verify and edit. Units: $ millions unless 'x'.)</p>\"),\n",
    "     widgets.HTML(\"<b>Revenue</b>\"), widgets.HBox([rev_c_in, rev_p_in]), rev_drv_in, \n",
    "     widgets.HTML(\"<hr style='margin:5px 0;'><b>EBITDA</b>\"), widgets.HBox([ebitda_c_in, ebitda_p_in]), ebitda_drv_in, \n",
    "     widgets.HTML(\"<hr style='margin:5px 0;'><b>FCF</b>\"), widgets.HBox([fcf_c_in, fcf_p_in]), fcf_drv_in, \n",
    "     widgets.HTML(\"<hr style='margin:5px 0;'><b>Leverage (x)</b>\"), widgets.HBox([lev_c_in, lev_p_in]), lev_drv_in, \n",
    "     widgets.HTML(\"<hr style='margin:5px 0;'><b>Benchmark Data (Optional)</b>\"), benchmark_input_area,\n",
    "])\n",
    "\n",
    "# Section 3 Layout: Report Generation\n",
    "report_section = widgets.VBox([\n",
    "     widgets.HTML(\"<b>Generate & Export Report:</b>\"),\n",
    "     widgets.HBox([gen_report_btn, nlg_report_btn]), \n",
    "     widgets.HTML(\"<br><b>Export Options:</b>\"),\n",
    "     widgets.HBox([export_md_btn, export_pdf_btn]),\n",
    "     analysis_status_label, \n",
    "     report_out \n",
    "])\n",
    "\n",
    "# Main Tabbed Interface\n",
    "main_tabs = widgets.Tab()\n",
    "main_tabs.children = [pr_section, manual_section, report_section]\n",
    "main_tabs.set_title(0, '1. Load & Parse') \n",
    "main_tabs.set_title(1, '2. Verify Data') \n",
    "main_tabs.set_title(2, '3. Generate Report') \n",
    "\n",
    "# --- Final App Layout ---\n",
    "app_layout = widgets.VBox([ \n",
    "    widgets.HTML(\"<h1>Financial Document Analysis Assistant v12</h1>\"), \n",
    "    model_load_section, \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    main_tabs, \n",
    "    # Global status labels can go here if needed, but most are in sections now\n",
    "]) \n",
    "\n",
    "# --- Link Buttons to Handlers ---\n",
    "# (Ensure handlers from Cell 8 are linked correctly to widgets from Cell 7)\n",
    "load_btn.on_click(on_load_models_click)\n",
    "file_upload.observe(on_upload_change, names='value') \n",
    "fetch_url_btn.on_click(on_fetch_url_click)\n",
    "parse_btn.on_click(on_parse_button_click)\n",
    "custom_q_btn.on_click(on_custom_qa_click) \n",
    "gen_report_btn.on_click(on_generate_click) \n",
    "nlg_report_btn.on_click(on_nlg_click)     \n",
    "export_md_btn.on_click(on_export_md_click) \n",
    "export_pdf_btn.on_click(on_export_pdf_click)\n",
    "\n",
    "# --- Display the UI --- \n",
    "print(\"Initializing UI Display...\") \n",
    "display(app_layout)\n",
    "# --- Post-Display Info --- \n",
    "if not TRANSFORMERS_AVAILABLE: print(\"\\nREMINDER: `transformers` missing/broken. AI features disabled.\")\n",
    "\n",
    "print(\"-\" * 20, \"Cell 9: UI Displayed - Ready for Interaction\", \"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# %%-- Single Cell Jupyter Notebook - Financial Analysis Assistant v12 - Final Syntax Fix --%%

# --- Imports and Setup ---
import ipywidgets as widgets
from IPython.display import display, clear_output, HTML
import math
import re
import time
import warnings
import html 
from collections import defaultdict 
# Optional: Try importing tokenizer for potentially better text chunking
try:
    from transformers import AutoTokenizer
    TOKENIZER_AVAILABLE = True
    print("INFO: `AutoTokenizer` found, will use for advanced chunking if needed.")
except ImportError:
    TOKENIZER_AVAILABLE = False
    print("INFO: `AutoTokenizer` not found. Using character-based chunking (less precise).")

# Suppress common warnings
warnings.filterwarnings("ignore", category=UserWarning, module='transformers') 
warnings.filterwarnings("ignore", category=FutureWarning) 

# --- Configuration Constants ---
# Model names 
MODEL_QA = "deepset/roberta-base-squad2" 
MODEL_SUMMARIZER = "sshleifer/distilbart-cnn-12-6"
MODEL_ZERO_SHOT = "facebook/bart-large-mnli"
MODEL_SENTIMENT = "ProsusAI/finbert"

# Parsing Strategy Options & Default
PARSE_STRATEGY_STANDARD = "Standard AI QA (Fastest AI)"
PARSE_STRATEGY_CHUNKED = "Full Document AI QA (Slow, Experimental)"
PARSE_STRATEGY_REGEX = "Regex Only (Fastest, Numbers Only)"
DEFAULT_PARSE_STRATEGY = PARSE_STRATEGY_STANDARD # Default to Standard QA

# QA Model Configuration
QA_CONTEXT_TRUNCATION_CHARS = 4000 # Character limit for Standard QA
QA_CHUNK_SIZE_CHARS = 2500       # Approx chunk size for Full Document QA
QA_CHUNK_OVERLAP_CHARS = 500      # Overlap between chunks for Full Document QA
QA_SCORE_THRESHOLD = 0.03         # Minimum confidence score (LOWERED to get more potential answers)

# Zero-Shot Classification Config
ZERO_SHOT_LABELS = ["Volume/Demand", "Pricing/Mix", "Cost Control", "M&A", "FX/Rates", "Capex", "WC", "Debt/Financing", "Product/Service", "Market/Comp.", "Inflation", "Supply Chain", "Restructuring"]
ZERO_SHOT_CONFIDENCE_THRESHOLD = 0.40 # Confidence threshold for displaying themes

# Text Analysis Config
TEXT_ANALYSIS_MAX_CHARS_ZS = 500 
TEXT_ANALYSIS_MAX_CHARS_SENTIMENT = 450 

# --- Dependency Check ---
TRANSFORMERS_AVAILABLE = False
try:
    try: import torch; print("INFO: PyTorch backend found.")
    except ImportError: import tensorflow; print("INFO: TensorFlow backend found.")
    from transformers import pipeline
    _ = pipeline('sentiment-analysis') # Basic check with default model
    TRANSFORMERS_AVAILABLE = True
    print("INFO: 'transformers' library seems functional.")
except ImportError as e: print(f"WARNING: Dependency issue ({e}). AI features disabled.")
except Exception as e: print(f"WARNING: Transformer init failed: {e}. AI features disabled.")

# --- Global Variables / Model Placeholders ---
pipelines = {"qa": None, "summarizer": None, "zero_shot": None, "sentiment": None}
models_loaded = False; model_load_error = False 
qa_tokenizer = None 

# --- Status Display Widgets ---
load_status_label = widgets.HTML(value="Status: Models not loaded.")
parse_status_label = widgets.HTML(value="Status: Ready.")
analysis_status_label = widgets.HTML(value="Status: Ready.")
custom_qa_status_label = widgets.HTML(value="") # Status for interactive QA

# --- Model Loading Function ---
def load_models(status_widget):
    """Loads required Hugging Face Transformer models and tokenizer."""
    global models_loaded, model_load_error, pipelines, qa_tokenizer
    # Pre-checks
    if not TRANSFORMERS_AVAILABLE: status_widget.value = "<span style='color: orange;'>Status: Cannot load - dependency issue.</span>"; return
    if models_loaded: status_widget.value = "<span style='color: green;'>Status: Models already loaded.</span>"; return
    # Reset state
    models_loaded = False; model_load_error = False; qa_tokenizer = None 
    model_list = {"qa": MODEL_QA, "summarizer": MODEL_SUMMARIZER, "zero_shot": MODEL_ZERO_SHOT, "sentiment": MODEL_SENTIMENT}
    total_start = time.time(); all_ok = True 
    
    # Load Tokenizer (Optional but preferred for chunking)
    if TOKENIZER_AVAILABLE:
        try: # --- Start Try block for Tokenizer ---
            print(f"Loading tokenizer for {MODEL_QA}..."); status_widget.value = f"Status: Loading tokenizer..."
            # --- Line broken for clarity and syntax safety ---
            qa_tokenizer = AutoTokenizer.from_pretrained(MODEL_QA) 
            print("-> Tokenizer loaded.") 
        except Exception as e: # --- Corresponding Except block ---
            print(f"Warning: Failed to load tokenizer: {e}. Using character chunking.")
            # Proceed without the tokenizer, chunking will be character-based
            qa_tokenizer = None # Ensure it's None if loading failed
    
    # Load Pipelines
    for key, name in model_list.items():
        start = time.time()
        try:
            status_widget.value = f"Status: Loading {key} ({name})..."; print(f"Loading {key}: {name}...")
            task = {"qa": "question-answering", "summarizer": "summarization", "zero_shot": "zero-shot-classification", "sentiment": "sentiment-analysis"}.get(key); assert task
            pipelines[key] = pipeline(task, model=name, tokenizer=name, device=-1) # Force CPU
            print(f"-> {key.upper()} OK ({time.time() - start:.1f}s)."); status_widget.value = f"Status: Loaded {key}."
        except Exception as e:
            print(f"ERROR loading {key} ({name}): {e}"); status_widget.value = f"<span style='color: red;'>Status: ERROR loading {key}.</span>"
            model_load_error = True; all_ok = False; pipelines[key] = None 
            
    total_elapsed = time.time() - total_start; final_color = "green" if all_ok else ("orange" if any(pipelines.values()) else "red")
    final_msg = "All models loaded!" if all_ok else ("Some loaded, errors occurred." if any(pipelines.values()) else "Failed to load models.")
    status_widget.value = f"<span style='color: {final_color};'>Status: {final_msg} ({total_elapsed:.1f}s)</span>"; models_loaded = all_ok and not model_load_error

# --- Helper Functions (Formatting) ---
def format_currency(v): 
    if not isinstance(v,(int,float)) or v is None or math.isnan(v) or math.isinf(v): return "$N/A"
    try: v_mm = v / 1e6; return f"${v_mm:,.1f}mm" if abs(v_mm) >= 0.05 else "$0.0mm"
    except: return "$N/A"
def format_percentage(v): 
    if not isinstance(v,(int,float)) or v is None or math.isnan(v): return "N/A%"
    try: return "Infinite %" if math.isinf(v) else f"{v:.1f}%"
    except: return "N/A%"
def format_leverage(v): 
    if not isinstance(v,(int,float)) or v is None or math.isnan(v) or math.isinf(v): return "N/Ax"
    try: return f"{v:.1f}x"
    except: return "N/Ax"

# --- REGEX FALLBACK IMPLEMENTATION ---
def extract_financial_figure_regex(text, keywords):
    num_pattern = r'[\$€£]?\s?\(?(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\)?\s*(million|billion|thousand|mn|bn|k)?'; window = 250; figures = [] 
    for kw in keywords:
        try:
            for m in re.finditer(r'\b' + re.escape(kw) + r'\b', text, re.IGNORECASE):
                s, _ = m.span(); start = max(0, s - window); end = min(len(text), s + window); seg = text[start:end]
                for nm in re.finditer(num_pattern, seg, re.IGNORECASE):
                    v_str, unit = nm.groups(); ns, _ = nm.span(); neg = (ns > 0 and seg[ns - 1] == '-') or nm.group(0).startswith('(')
                    try: v = float(v_str.replace(',', '')); v = -v if neg else v; unit = unit.lower() if unit else ""; v *= 1e3 if 'bil' in unit or unit=='bn' else (1e-3 if 'tho' in unit or unit=='k' else 1); figures.append({'value': v, 'pos': start + ns})
                    except ValueError: continue
        except Exception as e: print(f"Regex warn: {e}"); continue 
    if not figures: return None
    first_kw_m = re.search(r'\b' + re.escape(keywords[0]) + r'\b', text, re.IGNORECASE); kw_pos = first_kw_m.start() if first_kw_m else 0
    after = [f for f in figures if f['pos'] >= kw_pos]; best = min(after if after else figures, key=lambda f: abs(f['pos'] - kw_pos))
    return best['value']
def _parse_regex_only(text, status_widget):
    status_widget.value = "<span style='color: blue;'>Status: Running Regex...</span>"; print("Regex Only Strategy: Extracting...")
    extracted = defaultdict(lambda: None) 
    extracted['revenue_current'] = extract_financial_figure_regex(text, ["revenue", "total revenue", "net sales"]) 
    extracted['ebitda_current'] = extract_financial_figure_regex(text, ["ebitda", "adjusted ebitda"]) 
    extracted['fcf_current'] = extract_financial_figure_regex(text, ["free cash flow", "fcf"])
    extracted['cogs_current'] = extract_financial_figure_regex(text, ["cost of goods", "cogs"])
    extracted['opex_current'] = extract_financial_figure_regex(text, ["operating expenses", "opex", "sg&a"])
    extracted['da_current'] = extract_financial_figure_regex(text, ["depreciation", "amortization"])
    extracted['op_income_current'] = extract_financial_figure_regex(text, ["operating income", "ebit"])
    extracted['ocf_current'] = extract_financial_figure_regex(text, ["operating activities", "cash from operations"])
    extracted['capex_current'] = extract_financial_figure_regex(text, ["capital expenditure", "capex"])
    extracted['debt_total_current'] = extract_financial_figure_regex(text, ["total debt", "borrowings"])
    extracted['leverage_current'] = extract_financial_figure_regex(text, ["leverage ratio", "net debt to ebitda"]) 
    print("Regex Only Notice: Qualitative text and prior periods require manual input."); status_widget.value = "<span style='color: green;'>Status: Regex Complete.</span>"
    return extracted, "Regex Only"

# --- BASIC KEYWORD FALLBACK ---
def analyze_drivers_fallback(text):
    if not text or text.strip().lower() == 'n/a': return "<i>(No text)</i>"; text_lower = text.lower()
    kws = {"Vol/Demand": ["volume", "demand"], "Price/Mix": ["price", "mix"], "Cost": ["cost", "margin"], "M&A": ["acquisition"], "FX": ["fx", "currency"], "Capex": ["capex"], "WC": ["working capital"], "Debt/Lev": ["debt", "leverage"], "Prod/Market": ["product", "market"]}
    themes = [t for t, wds in kws.items() if any(w in text_lower for w in wds)]; return f"<i>(Fallback: Mentions {', '.join(themes)})</i>" if themes else "<i>(Fallback: No keywords)</i>"

# --- TRANSFORMER IMPLEMENTATIONS ---
def parse_financial_answer(ans, is_qual=False):
    if not ans: return None
    if is_qual: return ans.strip() 
    txt = ans.lower().replace('approx.','').strip(); txt = re.sub(r'[\$€£]', '', txt).strip(); txt = re.sub(r'\s+(dollars|euros|pounds)\b','', txt); txt = txt.replace('(','-').replace(')','') 
    num_pat = r'([-+]?\d{1,3}(?:,\d{3})*(?:\.\d+)?)\s*(million|billion|thousand|mn|bn|k)?'; m = re.search(num_pat, txt)
    if not m: m = re.search(r'([-+]?\d{1,3}(?:,\d{3})*(?:\.\d+)?)', txt); v_str = m.group(1) if m else None; unit = "" 
    else: v_str, u_m = m.groups(); unit = u_m if u_m else ""
    if not v_str: return None
    try: v = float(v_str.replace(',', ''))
    except: return None 
    unit = unit.lower(); v *= 1e3 if 'bil' in unit or unit=='bn' else (1e-3 if 'tho' in unit or unit=='k' else 1)
    return v

def _run_qa_on_context(qa_pipe, questions, context, status_widget, context_label="context"):
    """Runs QA questions against a single context string, returns best results."""
    extracted = defaultdict(lambda: None)
    q_total = sum(len(v) for v in questions.values()); q_ran = 0
    print(f"Running {q_total} QA variations on {context_label}...")
    for key, q_list in questions.items():
        best_ans = None; best_score = -1; is_qual = "text" in key 
        for q_idx, q in enumerate(q_list):
            q_ran += 1; 
            if (q_ran % 10 == 0): status_widget.value = f"<span style='color: blue;'>Status: Running QA ({q_ran}/{q_total} in {context_label})...</span>"
            try:
                res = qa_pipe(question=q, context=context, handle_impossible_answer=True); ans, score = res.get('answer'), res.get('score', 0)
                # print(f"  Q: {q} -> A: '{ans}' (Score: {score:.3f})") # Verbose
                if ans and score > QA_SCORE_THRESHOLD: # Use configured low threshold
                    parsed = parse_financial_answer(ans, is_qualitative=is_qual)
                    if parsed is not None and score > best_score: best_score = score; best_ans = parsed; # print(f"    -> New best for '{key}' (Score: {best_score:.3f}).") # Verbose
            except Exception as e: print(f"QA Error q='{q}': {e}")
            time.sleep(0.01) 
        extracted[key] = best_ans 
    return extracted

def _get_qa_questions():
    """Returns the dictionary of questions for the QA model."""
    q = defaultdict(list)
    q_fin = ['revenue_current', 'revenue_prior', 'ebitda_current', 'ebitda_prior', 'fcf_current', 'fcf_prior', 'cogs_current', 'cogs_prior', 'opex_current', 'opex_prior', 'da_current', 'da_prior', 'op_income_current', 'op_income_prior', 'ocf_current', 'ocf_prior', 'capex_current', 'capex_prior', 'debt_total_current', 'leverage_current']
    q_qual = ['revenue_drivers_text', 'ebitda_drivers_text', 'fcf_drivers_text', 'leverage_drivers_text']
    for k in q_fin + q_qual: q[k].append(f"What was the {k.replace('_', ' ').replace('text','explanation').replace('current','current period').replace('prior','prior year period')}?")
    q['revenue_current'].extend(["Net sales current period?", "Latest revenue figure?", "Total revenue?"]); q['revenue_prior'].extend(["Net sales prior year?", "Comparable prior revenue?", "Revenue last year?"])
    q['ebitda_current'].extend(["Adjusted EBITDA current period?", "Latest EBITDA?", "How much was EBITDA?"]); q['ebitda_prior'].extend(["Adjusted EBITDA prior year?", "Prior EBITDA?", "EBITDA last year?"])
    q['fcf_current'].extend(["Free cash flow current period?", "Latest FCF?"]); q['fcf_prior'].extend(["Free cash flow prior year?", "Prior FCF?"])
    q['revenue_drivers_text'].extend(["Explain revenue change.", "Factors impacting sales?", "What drove revenue?", "Describe revenue performance."])
    q['ebitda_drivers_text'].extend(["Explain EBITDA change.", "What affected margins?", "Drivers for profitability?", "Describe EBITDA performance."])
    q['fcf_drivers_text'].extend(["Explain FCF change.", "Reasons for cash flow?", "What impacted FCF?", "Describe free cash flow drivers."])
    q['leverage_drivers_text'].extend(["Explain leverage change.", "Reasons for net debt change?", "Factors affecting debt?", "Describe leverage drivers."])
    q['opex_current'].append("SG&A expense?"); q['opex_prior'].append("SG&A expense prior year?")
    q['ocf_current'].append("Cash flow from operations?"); q['ocf_prior'].append("Cash flow from operations prior year?")
    q['capex_current'].append("Capital expenditures?"); q['capex_prior'].append("Capital expenditures prior year?")
    q['leverage_current'].append("Net debt to EBITDA ratio?")
    return q

def _parse_standard_qa(text, status_widget):
    """Implements Standard AI QA strategy (runs on truncated text)."""
    status_widget.value = "<span style='color: blue;'>Status: Running Standard AI QA (Top ~4k Chars)...</span>"; print("Standard AI QA Strategy: Analyzing truncated text...")
    qa_pipe = pipelines.get("qa"); assert qa_pipe, "QA model not loaded."
    text_context = text[:QA_CONTEXT_TRUNCATION_CHARS] 
    questions = _get_qa_questions()
    extracted_data = _run_qa_on_context(qa_pipe, questions, text_context, status_widget, context_label="truncated context") 
    print(f"Standard AI QA Finished. Found {len([v for v in extracted_data.values() if v is not None])} potential answers (low confidence threshold).")
    status_widget.value = "<span style='color: green;'>Status: Standard AI QA Complete.</span>"
    return extracted_data, PARSE_STRATEGY_STANDARD

def _create_text_chunks(text, chunk_chars, overlap_chars):
    """Splits text into potentially overlapping chunks."""
    chunks = []; start = 0
    # Use tokenizer for chunking if available
    if qa_tokenizer:
        print("Using tokenizer for chunking...")
        # Simple token-based chunking (might truncate mid-word on overflow)
        # A more sophisticated approach would handle word boundaries better.
        max_tokens = qa_tokenizer.model_max_length - 50 # Leave buffer for question tokens
        tokens = qa_tokenizer(text, return_offsets_mapping=True, max_length=max_tokens*20, truncation=False) # Get all tokens/offsets initially
        offsets = tokens['offset_mapping']
        
        current_chunk_start_idx = 0
        while current_chunk_start_idx < len(offsets):
            # Find end token index respecting max_tokens for the chunk
            end_token_idx = min(current_chunk_start_idx + max_tokens -1, len(offsets) - 1)
            # Get character end position from offset mapping
            chunk_end_char = offsets[end_token_idx][1]
            # Get character start position
            chunk_start_char = offsets[current_chunk_start_idx][0]
            # Append the chunk text
            chunks.append(text[chunk_start_char:chunk_end_char])
            
            # Find start index for next chunk with overlap (e.g., overlap 1/4th of tokens)
            overlap_tokens = max_tokens // 4
            next_start_token_idx = current_chunk_start_idx + max_tokens - overlap_tokens
            # Ensure next start doesn't go backwards and exists
            current_chunk_start_idx = max(current_chunk_start_idx + 1, next_start_token_idx) 
            if current_chunk_start_idx >= len(offsets): break # Exit if we've passed the end
    else: # Fallback character chunking
        print("Using character-based chunking...")
        while True:
            end = start + chunk_chars; chunks.append(text[start:end])
            start += chunk_chars - overlap_chars 
            if end >= len(text): break 
    return chunks
    
def _parse_chunked_qa(text, status_widget):
    """Implements Full Document AI QA strategy using overlapping chunks."""
    status_widget.value = "<span style='color: blue;'>Status: Running Full Document AI QA (Chunking)... SLOW!</span>"; print(f"Full Document AI QA Strategy: Chunking text...")
    qa_pipe = pipelines.get("qa"); assert qa_pipe, "QA model not loaded."
    
    text_chunks = _create_text_chunks(text, QA_CHUNK_SIZE_CHARS, QA_CHUNK_OVERLAP_CHARS)
    print(f"Created {len(text_chunks)} chunks to process.")
    
    questions = _get_qa_questions()
    aggregated_results = defaultdict(lambda: {'answer': None, 'score': -1}) 
    total_q_estimate = sum(len(v) for v in questions.values()) * len(text_chunks); print(f"Estimated total QA calls: ~{total_q_estimate} (VERY SLOW!)")
    
    for i, chunk_ctx in enumerate(text_chunks):
        print(f"\nProcessing Chunk {i+1}/{len(text_chunks)}...")
        status_widget.value = f"<span style='color: blue;'>Status: Processing Chunk {i+1}/{len(text_chunks)}... (SLOW)</span>"
        # Run all questions on this chunk and aggregate scores
        q_total_chunk = sum(len(v) for v in questions.values()); q_ran_chunk = 0
        for key, q_list in questions.items():
            is_qual = "text" in key
            for q_idx, q in enumerate(q_list):
                q_ran_chunk += 1
                if (q_ran_chunk % 10 == 0): status_widget.value = f"<span style='color: blue;'>Status: Chunk {i+1} QA ({q_ran_chunk}/{q_total_chunk})...</span>"
                try:
                    res = qa_pipe(question=q, context=chunk_ctx, handle_impossible_answer=True); ans, score = res.get('answer'), res.get('score', 0)
                    if ans and score > QA_SCORE_THRESHOLD: 
                        parsed = parse_financial_answer(ans, is_qualitative=is_qual)
                        # Aggregate: Update if this answer has higher score for this key
                        if parsed is not None and score > aggregated_results[key]['score']: 
                            aggregated_results[key]['score'] = score; aggregated_results[key]['answer'] = parsed
                            print(f"    -> Updated best answer for '{key}' from chunk {i+1} (Score: {score:.3f}).")
                except Exception as e: print(f"QA Error q='{q}', chunk={i+1}: {e}")
                time.sleep(0.01) 

    final_extracted = defaultdict(lambda: None)
    print("\n--- Aggregated Best Answers Across Chunks ---"); found_count = 0
    for key, result_data in aggregated_results.items():
        if result_data['answer'] is not None:
            final_extracted[key] = result_data['answer'] ; found_count +=1
            print(f"  - {key}: {'(text)' if 'text' in key and len(str(result_data['answer']))>50 else result_data['answer']} (Score: {result_data['score']:.3f})")
    print("--- End Aggregation ---")
    print(f"\nFull Document AI QA Finished. Aggregated {found_count} non-empty values across {len(text_chunks)} chunks.")
    status_widget.value = "<span style='color: green;'>Status: Full Document AI QA Complete.</span>"
    return final_extracted, PARSE_STRATEGY_CHUNKED
    
# --- Transformer Analysis Function (reuse previous) ---
def analyze_drivers_transformer(text, status_widget):
    """Analyzes driver text using AI pipelines."""
    req_pipes = ["summarizer", "zero_shot", "sentiment"]; 
    if not all(pipelines.get(p) for p in req_pipes): return "<i>(AI analysis models not loaded)</i>"
    if not text or text.strip().lower() == 'n/a': return "<i>(No text)</i>"
    analysis = {}; status_widget.value = "<span style='color: blue;'>Status: Analyzing text...</span>"
    try: # Wrap entire analysis in try/except
        # Summarization
        try: analysis["Summary"] = f"<i>{html.escape(pipelines['summarizer'](text, max_length=80, min_length=15, do_sample=False)[0]['summary_text'])}</i>"
        except Exception as e: print(f"Summary fail: {e}"); analysis["Summary"] = "<i>Error</i>"
        # Zero-Shot
        try:
            text_trunc = text[:TEXT_ANALYSIS_MAX_CHARS_ZS] if len(text) > TEXT_ANALYSIS_MAX_CHARS_ZS else text; assert text_trunc.strip(), "Empty ZS text"
            results = pipelines['zero_shot'](text_trunc, candidate_labels=ZERO_SHOT_LABELS, multi_label=True); 
            themes = sorted([(l, s) for l, s in zip(results['labels'], results['scores']) if s > ZERO_SHOT_CONFIDENCE_THRESHOLD], key=lambda i: i[1], reverse=True)
            analysis["Themes"] = html.escape(", ".join([f"{l} ({s:.0%})" for l, s in themes])) if themes else "<i>None detected</i>"
        except Exception as e: print(f"Zero-shot fail: {e}"); analysis["Themes"] = "<i>Error</i>"
        # Sentiment
        try:
            chunks = [text[i:i+TEXT_ANALYSIS_MAX_CHARS_SENTIMENT] for i in range(0, len(text), TEXT_ANALYSIS_MAX_CHARS_SENTIMENT)]; sentiments = []; scores = []
            for chunk in chunks:
                 if not chunk.strip(): continue 
                 res = pipelines['sentiment'](chunk)[0]; sentiments.append(res['label']); scores.append(res['score']) 
            if sentiments: sentiment = max(set(sentiments), key=sentiments.count); avg_score = sum(s for s, lab in zip(scores, sentiments) if lab == sentiment) / sentiments.count(sentiment); analysis["Sentiment"] = f"{html.escape(sentiment.capitalize())} ({avg_score:.1%})" 
            else: analysis["Sentiment"] = "<i>N/A</i>"
        except Exception as e: print(f"Sentiment fail: {e}"); analysis["Sentiment"] = "<i>Error</i>"
    except Exception as e:
        print(f"Error during text analysis: {e}")
        return "<i>(Error during AI text analysis)</i>"
    # Format
    out = "<ul style='margin:0; padding-left:20px; font-size:0.9em;'>"; 
    if "Summary" in analysis: out += f"<li><b>Summary:</b> {analysis['Summary']}</li>"
    if "Themes" in analysis: out += f"<li><b>Themes:</b> {analysis['Themes']}</li>"
    if "Sentiment" in analysis: out += f"<li><b>Sentiment:</b> {analysis['Sentiment']}</li></ul>"
    return out if analysis else "<i>(Analysis failed)</i>"

# --- UI Widgets Setup ---
style = {'description_width': 'initial'}; layout_half = widgets.Layout(width='48%'); layout_text = widgets.Layout(width='98%', height='100px') 
pr_input = widgets.Textarea(description="Paste Text:", placeholder="Paste press release...", layout=widgets.Layout(width='98%', height='200px'), style=style)
parse_strategy_selector = widgets.RadioButtons(options=[PARSE_STRATEGY_STANDARD, PARSE_STRATEGY_CHUNKED, PARSE_STRATEGY_REGEX], value=DEFAULT_PARSE_STRATEGY, description='Strategy:', style=style, layout=widgets.Layout(width='max-content'))
parse_btn = widgets.Button(description="Parse Press Release", button_style='info', icon='paste', tooltip="Extract data")
parse_out = widgets.Output() 
custom_q_in = widgets.Text(description="Question:", placeholder="Ask about the text...", layout=widgets.Layout(width='80%'), style=style)
custom_q_btn = widgets.Button(description="Ask AI", button_style='primary', tooltip="Run custom question")
# ***** ENSURING DEFINITION FOR custom_qa_output *****
custom_q_out = widgets.Output() 
# Data Input Fields
rev_c_in = widgets.FloatText(description="Rev (C, $mm):", style=style, layout=layout_half)
rev_p_in = widgets.FloatText(description="Rev (P, $mm):", style=style, layout=layout_half)
rev_drv_in = widgets.Textarea(description="Rev Drivers:", placeholder="(Auto/Manual)", style=style, layout=layout_text)
ebitda_c_in = widgets.FloatText(description="EBITDA (C, $mm):", style=style, layout=layout_half)
ebitda_p_in = widgets.FloatText(description="EBITDA (P, $mm):", style=style, layout=layout_half)
ebitda_drv_in = widgets.Textarea(description="EBITDA Drivers:", placeholder="(Auto/Manual)", style=style, layout=layout_text)
fcf_c_in = widgets.FloatText(description="FCF (C, $mm):", style=style, layout=layout_half)
fcf_p_in = widgets.FloatText(description="FCF (P, $mm):", style=style, layout=layout_half)
fcf_drv_in = widgets.Textarea(description="FCF Drivers:", placeholder="(Auto/Manual)", style=style, layout=layout_text)
lev_c_in = widgets.FloatText(description="Leverage (C, x):", style=style, layout=layout_half)
lev_p_in = widgets.FloatText(description="Leverage (P, x):", style=style, layout=layout_half)
lev_drv_in = widgets.Textarea(description="Leverage Drivers:", placeholder="(Auto/Manual)", style=style, layout=layout_text)
gen_btn = widgets.Button(description="Generate Summary", button_style='success', icon='cogs', tooltip="Generate analysis")
analysis_out = widgets.Output() 

# --- Event Handlers ---
def on_load_models_click(b):
    """Handles 'Load Models' button."""
    b.disabled = True; b.description = "Loading..."; b.icon = "spinner"
    load_models(load_status_label) 
    b.disabled = False; b.description = "Load Models"; b.icon = "download"
    analysis_status_label.value = "Status: Ready." # Reset status

def on_parse_button_click(b):
    """Handles 'Parse Press Release' button using selected strategy."""
    parse_out.clear_output(wait=True); analysis_out.clear_output() 
    with parse_out: 
        parse_strategy = parse_strategy_selector.value 
        parse_status_label.value = f"<span style='color: blue;'>Status: Parsing ({parse_strategy})...</span>"; print(f"Initiating parse: {parse_strategy}")
        pr_txt = pr_input.value
        if not pr_txt or not pr_txt.strip(): print("Error: Empty text."); parse_status_label.value = "<span style='color: red;'>Status: Error - Empty text.</span>"; return
        
        extracted = defaultdict(lambda: None); 
        method = "Unknown"; success = False # <<< METHOD INITIALIZED
        
        # Call selected parsing function
        try:
            start_parse_time = time.time()
            if parse_strategy == PARSE_STRATEGY_STANDARD:
                if not (TRANSFORMERS_AVAILABLE and models_loaded and pipelines.get("qa")): raise RuntimeError("Standard AI QA requires loaded QA model.")
                extracted, method = _parse_standard_qa(pr_txt, parse_status_label)
            elif parse_strategy == PARSE_STRATEGY_CHUNKED:
                if not (TRANSFORMERS_AVAILABLE and models_loaded and pipelines.get("qa")): raise RuntimeError("Full Document AI QA requires loaded QA model.")
                extracted, method = _parse_chunked_qa(pr_txt, parse_status_label)
            elif parse_strategy == PARSE_STRATEGY_REGEX:
                 extracted, method = _parse_regex_only(pr_txt, parse_status_label)
            else: raise ValueError(f"Unknown strategy: {parse_strategy}")
            success = True 
            parse_time = time.time() - start_parse_time
            print(f"Parsing strategy '{method}' completed in {parse_time:.1f} seconds.")
        except Exception as e:
             print(f"ERROR during parsing strategy '{parse_strategy}': {e}")
             parse_status_label.value = f"<span style='color: red;'>Status: Error during parsing. Check console.</span>"; success = False
             method = f"Failed ({parse_strategy})" # Update method to reflect failure
        
        # --- Estimation Logic (Applied after parsing attempt) ---
        final = dict(extracted); log = []; est_done = False
        if success: # Only attempt estimation if parsing didn't hard fail
            print("\nAttempting estimations for missing primary figures..."); 
            def _valid(*a): return all(isinstance(x,(int,float)) and x is not None and not math.isnan(x) for x in a)
            # Est EBITDA(C)
            if final.get('ebitda_current') is None:
                opinc, da, rev, cogs, opex = (final.get(k) for k in ['op_income_current', 'da_current', 'revenue_current', 'cogs_current', 'opex_current'])
                if _valid(opinc, da): est = opinc + da; final['ebitda_current'] = est; log.append(f"Est. EBITDA(C)=OpInc({opinc:.1f})+D&A({da:.1f})={est:.1f}"); est_done=True
                elif _valid(rev, cogs, opex): base = rev - cogs - opex; da_val = da if _valid(da) else 0; est = base + da_val; final['ebitda_current'] = est; log.append(f"Est. EBITDA(C)=Rev-Exp+(D&A:{da_val:.1f})={est:.1f}"); est_done=True
            # Est EBITDA(P) 
            if final.get('ebitda_prior') is None:
                 opinc_p, da_p = (final.get(k) for k in ['op_income_prior', 'da_prior'])
                 if _valid(opinc_p, da_p): 
                     est = opinc_p + da_p; final['ebitda_prior'] = est; log.append(f"Est. EBITDA(P)=OpInc_p({opinc_p:.1f})+D&A_p({da_p:.1f})={est:.1f}"); est_done=True
            # Est FCF(C) 
            if final.get('fcf_current') is None:
                 ocf, capex = (final.get(k) for k in ['ocf_current', 'capex_current'])
                 if _valid(ocf, capex): 
                      est = ocf - abs(capex); final['fcf_current'] = est; log.append(f"Est. FCF(C)=OCF({ocf:.1f})-Capex({abs(capex):.1f})={est:.1f}"); est_done=True
            # Est FCF(P) 
            if final.get('fcf_prior') is None:
                 ocf_p, capex_p = (final.get(k) for k in ['ocf_prior', 'capex_prior'])
                 if _valid(ocf_p, capex_p): 
                      est = ocf_p - abs(capex_p); final['fcf_prior'] = est; log.append(f"Est. FCF(P)=OCF_p({ocf_p:.1f})-Capex_p({abs(capex_p):.1f})={est:.1f}"); est_done=True
            # Est Lev(C) 
            if final.get('leverage_current') is None:
                debt, ebitda = (final.get(k) for k in ['debt_total_current', 'ebitda_current']) 
                if _valid(debt, ebitda) and abs(ebitda or 0) > 1e-6: 
                    est = debt / ebitda 
                    if 0 < est < 20: # Sanity check
                        final['leverage_current'] = est; log.append(f"Est. Lev(C)=Debt({debt:.1f})/EBITDA({ebitda:.1f})={est:.1f}x"); est_done = True
                    else: log.append(f"Est. Lev(C) skipped (ratio {est:.1f}x unreal.)")
            # Log estimations
            if est_done: print("\n--- Estimations Performed ---"); [print(f"- {l}") for l in log]; print("---")
            else: print("\nNo estimations performed.")

        # --- Populate UI ---
        # Only proceed if parsing didn't fail catastrophically
        if method != "Failed (All methods)": 
            w_map = {'revenue_current': rev_c_in, 'revenue_prior': rev_p_in, 'ebitda_current': ebitda_c_in, 'ebitda_prior': ebitda_p_in, 'fcf_current': fcf_c_in, 'fcf_prior': fcf_p_in, 'leverage_current': lev_c_in, 'leverage_prior': lev_p_in, 'revenue_drivers_text': rev_drv_in, 'ebitda_drivers_text': ebitda_drv_in, 'fcf_drivers_text': fcf_drv_in, 'leverage_drivers_text': lev_drv_in}
            print("\nPopulating UI fields:"); pop_count = 0
            for k, w in w_map.items():
                val = final.get(k); est = any(k.split('_')[0].lower() in l.lower() for l in log if k.lower() in l.lower()) 
                if val is not None:
                    try: 
                        # Format FloatText values to 2 decimal places for display consistency
                        w.value = float(f"{val:.2f}") if isinstance(w, widgets.FloatText) and isinstance(val, float) else val
                        pop_count += 1; 
                        # Show preview of text if long, otherwise show number/short text
                        val_display = f"'{str(val)[:50]}...'" if isinstance(val, str) and len(val)>50 else val
                        print(f"  - Set {k}{' (Est.)' if est else ''}: {val_display}")
                    except Exception as set_e: print(f"  - Error setting widget for {k}: {set_e}"); w.value = None # Clear widget on error
            
            print(f"\nPopulated {pop_count} fields. Method: {method}"); 
            print("\n>>> !! CRITICAL: Review ALL fields. Edit as needed, especially estimations and extracted text. !! <<<")
            # Final status update reflects success
            parse_status_label.value = f"<span style='color: green;'>Status: Parse/Estimate OK ({method}). VERIFY VALUES.</span>"
        
        elif success: # Parsing ran but maybe returned empty dict
             parse_status_label.value = f"<span style='color: orange;'>Status: Parsed ({method}), but no data extracted/estimated.</span>"
        
        # else: Status already set for parsing failure cases
        
        analysis_status_label.value = "Status: Ready." # Reset analysis status

def on_custom_qa_click(b):
    """Handles 'Ask AI' button for interactive QA."""
    custom_qa_output.clear_output(wait=True) # Uses defined custom_qa_output
    custom_qa_status_label.value = "<span style='color: blue;'>Processing...</span>"
    with custom_qa_output: # Uses defined custom_qa_output
        q = custom_q_in.value; txt = pr_input.value; qa_pipe = pipelines.get("qa")
        # Validations
        if not q or not q.strip(): print("ERROR: Enter question."); custom_qa_status_label.value = "<span style='color: red;'>Status: Enter question.</span>"; return
        if not txt or not txt.strip(): print("ERROR: Paste text first."); custom_qa_status_label.value = "<span style='color: red;'>Status: Paste text.</span>"; return
        if not qa_pipe: print("ERROR: QA model not loaded."); custom_qa_status_label.value = "<span style='color: red;'>Status: Load QA model.</span>"; return
        print(f"Asking AI: '{html.escape(q)}'"); 
        try:
            # Run QA on the full text for interactive questions
            res = qa_pipe(question=q, context=txt, handle_impossible_answer=True)
            ans, score = res.get('answer'), res.get('score', 0)
            print(f"\nAnswer: {html.escape(ans if ans else '(No answer found)')}")
            print(f"Confidence: {score:.3f}")
            if not ans or score < QA_SCORE_THRESHOLD: print("(Low confidence or no answer found)")
            custom_qa_status_label.value = f"<span style='color: {'green' if ans and score >= QA_SCORE_THRESHOLD else 'orange'};'>Status: Custom QA complete.</span>"
        except Exception as e: print(f"\nERROR: {e}"); custom_qa_status_label.value = "<span style='color: red;'>Status: Custom QA Error.</span>"

def on_generate_click(b):
    """Handles 'Generate Analysis Summary' button."""
    analysis_out.clear_output(wait=True) 
    with analysis_out: 
        analysis_status_label.value = "<span style='color: blue;'>Status: Generating...</span>"; print("Generating Summary...")
        # Get Values & Validate
        try:
            def get_units(w): v=w.value; return v * 1e6 if isinstance(v,(int,float)) and v is not None and not math.isnan(v) else None
            rev_c, rev_p = get_units(rev_c_in), get_units(rev_p_in); ebitda_c, ebitda_p = get_units(ebitda_c_in), get_units(ebitda_p_in)
            fcf_c, fcf_p = get_units(fcf_c_in), get_units(fcf_p_in); 
            lev_c = lev_c_in.value if isinstance(lev_c_in.value,(int,float)) and not math.isnan(lev_c_in.value) else None
            lev_p = lev_p_in.value if isinstance(lev_p_in.value,(int,float)) and not math.isnan(lev_p_in.value) else None
        except Exception as e: print(f"Input Error: {e}"); analysis_status_label.value = f"<span style='color: red;'>Status: Input Error</span>"; return
        qual_in = {"Rev": rev_drv_in.value or "N/A", "EBITDA": ebitda_drv_in.value or "N/A", "FCF": fcf_drv_in.value or "N/A", "Lev": lev_drv_in.value or "N/A"}
        
        # Analyze Qualitative
        analysis_status_label.value = "<span style='color: blue;'>Status: Analyzing text...</span>"; qual_an = {}; method = "Basic Fallback" 
        analysis_ok = TRANSFORMERS_AVAILABLE and models_loaded and all(pipelines.get(k) for k in ["summarizer", "zero_shot", "sentiment"])
        if analysis_ok:
            print("Attempting AI analysis..."); method = "Transformer (AI)"
            for k, txt in qual_in.items():
                analysis_status_label.value = f"<span style='color: blue;'>Status: Analyzing '{k}'...</span>"
                try: qual_an[k] = analyze_drivers_transformer(txt, analysis_status_label) 
                except Exception as e: print(f"AI analysis fail {k}: {e}"); qual_an[k] = analyze_drivers_fallback(txt); method = "Mixed"
        else:
             reason = "(Lib N/A)" if not TRANSFORMERS_AVAILABLE else "(Models not loaded)"; print(f"Using basic analysis {reason}."); analysis_status_label.value = f"<span style='color: orange;'>Status: Basic analysis {reason}...</span>"
             for k, txt in qual_in.items(): qual_an[k] = analyze_drivers_fallback(txt)
        analysis_status_label.value = f"<span style='color: blue;'>Status: Text analysis done ({method}).</span>"

        # Calculations
        analysis_status_label.value = "<span style='color: blue;'>Status: Calculating...</span>"
        try:
            def calc_chg(c, p):
                if not all(isinstance(x,(int,float)) and x is not None and not math.isnan(x) for x in [c, p]): return None, None
                delta = c - p; return (float('inf') if c>1e-9 else (float('-inf') if c<-1e-9 else 0.0)) if abs(p)<1e-9 else (delta/abs(p)*100), delta
            rev_pc, _ = calc_chg(rev_c, rev_p); ebitda_pc, _ = calc_chg(ebitda_c, ebitda_p); fcf_pc, _ = calc_chg(fcf_c, fcf_p)
            lev_d = (lev_c - lev_p) if all(isinstance(x,(int,float)) and x is not None and not math.isnan(x) for x in [lev_c, lev_p]) else None
            margin_c = (ebitda_c / rev_c * 100) if rev_c and abs(rev_c) > 1e-9 and ebitda_c is not None else None
            margin_p = (ebitda_p / rev_p * 100) if rev_p and abs(rev_p) > 1e-9 and ebitda_p is not None else None
        except Exception as e: print(f"Calc Error: {e}"); analysis_status_label.value = f"<span style='color: red;'>Status: Calc Error</span>"; return

        analysis_status_label.value = "<span style='color: blue;'>Status: Formatting...</span>"

        # Generate Output HTML
        out = f"<h2>Financial Performance Summary</h2><p style='font-size:0.9em; color:grey;'><i>(Text analysis: {method})</i></p>"
        def fmt_qual(lbl, k): txt = qual_in.get(k, "N/A"); analysis = qual_an.get(k, ""); block = f"<div style='margin-left:15px; margin-top:3px; font-size:0.9em; color:#333; border-left: 2px solid #eee; padding-left: 5px;'><b>AI Analysis:</b> {analysis}</div>" if analysis and "<i>(" not in analysis and "N/A" not in analysis else (analysis if "<i>(" in analysis else ""); esc_txt = html.escape(txt) if txt else "N/A"; txt_disp = f"<p style='margin:2px 0; white-space:pre-wrap;'>{esc_txt}</p>"; return f"<li><b>{lbl}:</b> {txt_disp}{block}</li>"

        # Revenue
        out += "<h3>Revenue</h3><ul>"; s1 = "<li>Data incomplete.</li>"
        if rev_pc is not None: 
            if abs(rev_p or 0)<1e-9: s1 = f"<li>Revenue: <strong>{format_currency(rev_c)}</strong> (vs $0.0mm prior).</li>"
            else: d = "increased" if rev_pc >= 0 else "decreased"; d = "was ~flat" if abs(rev_pc) < 0.05 else d; s1 = f"<li>Revenue {d} <strong>{format_percentage(abs(rev_pc))}</strong> YoY to <strong>{format_currency(rev_c)}</strong> (from {format_currency(rev_p)}).</li>"
        elif rev_c is not None: s1 = f"<li>Current Revenue: <strong>{format_currency(rev_c)}</strong> (Prior N/A).</li>"
        out += s1; out += fmt_qual("Drivers/Factors", "Rev"); out += "</ul>"

        # EBITDA
        out += "<h3>EBITDA & Margin</h3><ul>"; s1 = "<li>Data incomplete.</li>"; s2 = "<li>Margin N/A.</li>" 
        if ebitda_pc is not None: 
            if abs(ebitda_p or 0)<1e-9: s1 = f"<li>EBITDA: <strong>{format_currency(ebitda_c)}</strong> (vs $0.0mm prior).</li>"
            else: d = "increased" if ebitda_pc >= 0 else "decreased"; d = "was ~flat" if abs(ebitda_pc) < 0.05 else d; s1 = f"<li>EBITDA {d} <strong>{format_percentage(abs(ebitda_pc))}</strong> YoY to <strong>{format_currency(ebitda_c)}</strong> (from {format_currency(ebitda_p)}).</li>"
            if margin_c is not None and margin_p is not None: margin_d = margin_c - margin_p; bps = margin_d * 100; s2 = f"<li>Margin stable at ~{format_percentage(margin_c)}.</li>" if abs(margin_d)<0.05 else f"<li>Margin {'expanded' if margin_d>0 else 'contracted'} {abs(bps):.0f} bps YoY to <strong>{format_percentage(margin_c)}</strong>.</li>"
            elif margin_c is not None: s2 = f"<li>Current margin: {format_percentage(margin_c)}.</li>"
        elif ebitda_c is not None: 
            s1 = f"<li>Current EBITDA: <strong>{format_currency(ebitda_c)}</strong> (Prior N/A).</li>"
            if margin_c is not None: s2 = f"<li>Current margin: {format_percentage(margin_c)}.</li>"
        out += s1; out += s2; out += fmt_qual("Drivers/Factors", "EBITDA"); out += "</ul>"
        
        # FCF
        out += "<h3>Free Cash Flow</h3><ul>"; s1 = "<li>Data incomplete.</li>"
        if fcf_pc is not None and fcf_c is not None and fcf_p is not None: 
            neg_p=fcf_p<-1e-9; neg_c=fcf_c<-1e-9; zero_p=abs(fcf_p)<1e-9
            if neg_p and not neg_c: s1 = f"<li>FCF improved to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
            elif not neg_p and neg_c: s1 = f"<li>FCF declined to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
            elif zero_p: s1 = f"<li>FCF: <strong>{format_currency(fcf_c)}</strong> (vs $0.0mm prior).</li>"
            elif neg_p and neg_c: d="improved" if fcf_c>fcf_p else "worsened"; s1 = f"<li>FCF {d} to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
            else: d="increased" if fcf_pc >= 0 else "decreased"; d="was ~flat" if abs(fcf_pc)<0.05 else d; s1 = f"<li>FCF {d} <strong>{format_percentage(abs(fcf_pc))}</strong> YoY to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
        elif fcf_c is not None: s1 = f"<li>Current FCF: <strong>{format_currency(fcf_c)}</strong> (Prior N/A).</li>"
        out += s1; out += fmt_qual("Drivers/Factors", "FCF"); out += "</ul>"

        # Leverage
        out += "<h3>Leverage</h3><ul>"; s1 = "<li>Data incomplete.</li>"
        if lev_d is not None and lev_c is not None and lev_p is not None: 
            delta=abs(lev_d); s1=f"<li>Leverage stable at ~<strong>{format_leverage(lev_c)}</strong>.</li>" if delta<0.05 else (f"<li>Leverage increased {delta:.1f}x YoY to <strong>{format_leverage(lev_c)}</strong>.</li>" if lev_d>0 else f"<li>Leverage decreased {delta:.1f}x YoY to <strong>{format_leverage(lev_c)}</strong>.</li>")
        elif lev_c is not None: s1 = f"<li>Current Leverage: <strong>{format_leverage(lev_c)}</strong> (Prior N/A).</li>"
        out += s1; out += fmt_qual("Drivers/Factors", "Lev"); out += "</ul>"
        
        # Display
        clear_output(wait=True); display(HTML(out)); 
        analysis_status_label.value = "<span style='color: green;'>Status: Analysis complete.</span>"; print("\nAnalysis finished.") 

# --- UI Layout Construction ---
# --- Model Loading ---
load_btn = widgets.Button(description="Load AI Models", button_style='warning', icon='download', tooltip="Load AI models")
# --- Parsing Section ---
pr_section = widgets.VBox([
    widgets.HTML("<b>Press Release Text & Parsing Control</b>"), 
    pr_input, 
    widgets.HTML("<br><b>Select Parsing Strategy:</b>"), 
    parse_strategy_selector, # Radio buttons
    parse_btn, 
    parse_status_label, 
    parse_out, 
    # Interactive QA Sub-section
    widgets.HTML("<hr style='margin: 10px 0;'><b>Interactive Follow-up QA:</b>"), 
    widgets.HTML("<p style='font-size:0.9em;'>Ask specific questions about the text above (AI models must be loaded).</p>"),
    widgets.HBox([custom_q_in, custom_q_btn]), 
    custom_qa_status_label, 
    custom_q_out # Output for custom QA results
])
# --- Data Input/Verification Section ---
manual_section = widgets.VBox([
     widgets.HTML("<b>Enter / Verify Financial Data:</b>"),
     widgets.HTML("<b>Revenue</b> ($mm)"), widgets.HBox([rev_c_in, rev_p_in]), rev_drv_in, 
     widgets.HTML("<hr style='margin:5px 0; border-top:1px dashed #ccc;'><b>EBITDA</b> ($mm)"), widgets.HBox([ebitda_c_in, ebitda_p_in]), ebitda_drv_in, 
     widgets.HTML("<hr style='margin:5px 0; border-top:1px dashed #ccc;'><b>FCF</b> ($mm)"), widgets.HBox([fcf_c_in, fcf_p_in]), fcf_drv_in, 
     widgets.HTML("<hr style='margin:5px 0; border-top:1px dashed #ccc;'><b>Leverage</b> (x)"), widgets.HBox([lev_c_in, lev_p_in]), lev_drv_in, 
])
# --- Accordion Structure ---
accordion = widgets.Accordion(children=[pr_section, manual_section]); 
accordion.set_title(0, '1. Press Release & Parsing Tools'); 
accordion.set_title(1, '2. Data Input / Verification'); 
accordion.selected_index = 1 
# --- Final App Layout ---
app = widgets.VBox([ 
    widgets.HTML("<h2>Financial Analysis Assistant v12</h2>"), # Version number updated
    widgets.HTML("<b>AI Model Control:</b>"), widgets.HBox([load_btn, load_status_label]), widgets.HTML("<hr>"), 
    accordion, widgets.HTML("<hr>"), 
    gen_btn, analysis_status_label, analysis_out 
])

# --- Link Buttons & Display ---
load_btn.on_click(on_load_models_click)
parse_btn.on_click(on_parse_button_click)
custom_q_btn.on_click(on_custom_qa_click) # Link interactive QA button
gen_btn.on_click(on_generate_click)
print("Displaying UI...") 
display(app)
# --- Post-Display Info ---
if not TRANSFORMERS_AVAILABLE: print("\nREMINDER: `transformers` missing/broken. Advanced AI features disabled.")

# %%-- End of Single Cell --%%

# %%-- Single Cell Jupyter Notebook - Transformer Enhanced Financial Analysis v5 - Best Practices --%%

# --- Imports and Setup ---
import ipywidgets as widgets
from IPython.display import display, clear_output, HTML
import math
import re
import time
import warnings
import html # For escaping user text in output
from collections import defaultdict # For easier handling of extracted data

# Suppress specific warnings frequently seen with transformers
warnings.filterwarnings("ignore", category=UserWarning, module='transformers') 
warnings.filterwarnings("ignore", category=FutureWarning) 

# --- Configuration Constants ---
# Model names for Hugging Face Hub
MODEL_QA = "deepset/roberta-base-squad2"
MODEL_SUMMARIZER = "sshleifer/distilbart-cnn-12-6"
MODEL_ZERO_SHOT = "facebook/bart-large-mnli"
MODEL_SENTIMENT = "ProsusAI/finbert"

# QA Model Configuration
QA_CONTEXT_MAX_CHARS = 3800  # Approx. character limit for QA context window
QA_SCORE_THRESHOLD = 0.05   # Minimum confidence score to accept QA answer

# Zero-Shot Classification Configuration
ZERO_SHOT_LABELS = [
    "Volume / Demand", "Pricing / Mix", "Cost Control / Efficiency", 
    "M&A / Divestitures", "FX / Rates", "Capex / Investment", 
    "Working Capital", "Debt / Financing", "Product / Service Factors", 
    "Market Conditions / Competition", "Inflation Impact", "Supply Chain", 
    "Restructuring"
]
ZERO_SHOT_CONFIDENCE_THRESHOLD = 0.40 # Minimum score to show a theme

# Text Analysis Configuration
TEXT_ANALYSIS_MAX_CHARS_ZS = 500 # Max characters for Zero-Shot input
TEXT_ANALYSIS_MAX_CHARS_SENTIMENT = 450 # Approx. max characters per chunk for Sentiment

# --- Dependency Check ---
TRANSFORMERS_AVAILABLE = False
try:
    # Check for backend first
    try: import torch; print("INFO: PyTorch backend found.")
    except ImportError: import tensorflow; print("INFO: TensorFlow backend found.")
    # Check for transformers library and basic pipeline initialization
    from transformers import pipeline
    _ = pipeline('sentiment-analysis', model='distilbert/distilbert-base-uncased-finetuned-sst-2-english') # Minimal check
    TRANSFORMERS_AVAILABLE = True
    print("INFO: 'transformers' library is installed and functional.")
except ImportError as e: 
    print(f"WARNING: Dependency issue ({e}). Advanced AI features disabled.")
    print("--> Please install necessary libraries (`pip install transformers torch` or `pip install transformers tensorflow`) and restart kernel.")
except Exception as e: 
    print(f"WARNING: Transformer pipeline init failed: {e}. Advanced AI features may be unstable or disabled.")
    print("--> Ensure 'transformers' and a backend ('torch' or 'tensorflow') are correctly installed.")

# --- Global Variables / Model Placeholders ---
# Dictionary to hold the initialized transformer pipelines
pipelines = {
    "qa": None,
    "summarizer": None,
    "zero_shot": None,
    "sentiment": None
}
models_loaded = False      # Flag to track if models have been loaded
model_load_error = False # Flag to track if any errors occurred during loading

# --- Status Display Widgets ---
# These widgets provide feedback to the user in the UI
load_status_label = widgets.HTML(value="Status: Models not loaded.")
parse_status_label = widgets.HTML(value="Status: Ready for Press Release Parsing.")
analysis_status_label = widgets.HTML(value="Status: Ready for Analysis Generation.")

# --- Model Loading Function ---
def load_models(status_widget):
    """
    Loads the required Hugging Face Transformer models using the pipeline API.
    Updates the status_widget with progress and results.
    Uses constants defined above for model names. Forces CPU usage.
    """
    global models_loaded, model_load_error, pipelines
    
    # Pre-checks
    if not TRANSFORMERS_AVAILABLE:
        status_widget.value = "<span style='color: orange;'>Status: Cannot load models - dependency issue.</span>"
        print("ERROR: Transformers library not available. Cannot load models.")
        return
    if models_loaded:
        status_widget.value = "<span style='color: green;'>Status: Models already loaded.</span>"
        return
    
    # Reset status flags
    models_loaded = False 
    model_load_error = False 
    
    # Define models to load
    model_list = {
        "qa": MODEL_QA,
        "summarizer": MODEL_SUMMARIZER,
        "zero_shot": MODEL_ZERO_SHOT,
        "sentiment": MODEL_SENTIMENT
    }
    
    total_start_time = time.time()
    all_models_successfully_loaded = True 
    
    # Loop through models and attempt loading
    for key, model_name in model_list.items():
        start_time = time.time()
        try:
            status_widget.value = f"Status: Loading {key} model ({model_name})... Please wait."
            print(f"Loading {key} model: {model_name}...")
            
            # Determine the pipeline task based on the key
            task = {"qa": "question-answering", "summarizer": "summarization", 
                    "zero_shot": "zero-shot-classification", "sentiment": "sentiment-analysis"}.get(key)
            if not task: raise ValueError(f"Internal error: Unknown model key '{key}'")
                
            # Load pipeline, explicitly setting device to CPU (-1) for broader compatibility
            # Remove device=-1 if a working GPU setup is available and desired.
            pipelines[key] = pipeline(task, model=model_name, tokenizer=model_name, device=-1) 
            
            elapsed = time.time() - start_time
            print(f"-> {key.upper()} model loaded successfully in {elapsed:.1f}s.")
            status_widget.value = f"Status: Successfully loaded {key} model."
            
        except Exception as e:
            print(f"ERROR loading {key} model ({model_name}): {e}")
            status_widget.value = f"<span style='color: red;'>Status: ERROR loading {key} model. Check console output above.</span>"
            model_load_error = True
            all_models_successfully_loaded = False
            pipelines[key] = None # Ensure pipeline is None if loading failed
            
    # Report final status
    total_elapsed = time.time() - total_start_time
    if all_models_successfully_loaded:
        models_loaded = True
        status_widget.value = f"<span style='color: green;'>Status: All Transformer models loaded successfully! ({total_elapsed:.1f}s)</span>"
        print(f"Total model loading time: {total_elapsed:.1f}s")
    elif any(p is not None for p in pipelines.values()): # Some loaded, some failed
         status_widget.value = f"<span style='color: orange;'>Status: Some models loaded, but errors occurred. Check console. ({total_elapsed:.1f}s)</span>"
         print(f"Total loading time (with errors): {total_elapsed:.1f}s")
    else: # All failed
         status_widget.value = f"<span style='color: red;'>Status: Failed to load any models. Check installation and console. ({total_elapsed:.1f}s)</span>"
         print(f"Total loading time (all failed): {total_elapsed:.1f}s")

# --- Helper Functions (Formatting) ---
def format_currency(value):
    """Formats a number (assumed in base units) into $ millions string."""
    if not isinstance(value, (int, float)) or value is None or math.isnan(value) or math.isinf(value): return "$N/A"
    try: 
        # Convert base units to millions for display
        value_in_millions = value / 1_000_000
        return f"${value_in_millions:,.1f}mm" if abs(value_in_millions) >= 0.05 else "$0.0mm" # Format with 1 decimal
    except (TypeError, ValueError): return "$N/A"

def format_percentage(value):
    """Formats a number as a percentage string."""
    if not isinstance(value, (int, float)) or value is None or math.isnan(value): return "N/A%"
    try: 
        if math.isinf(value): return "Infinite %" if value > 0 else "-Infinite %"
        return f"{value:.1f}%" # Format with 1 decimal
    except (TypeError, ValueError): return "N/A%"

def format_leverage(value):
    """Formats a leverage ratio number."""
    if not isinstance(value, (int, float)) or value is None or math.isnan(value) or math.isinf(value): return "N/Ax"
    try: 
        return f"{value:.1f}x" # Format with 1 decimal
    except (TypeError, ValueError): return "N/Ax"

# --- REGEX FALLBACK IMPLEMENTATION ---
# This section provides basic parsing if Transformers are unavailable or fail.
# It's less accurate, especially for qualitative text and prior periods.

def extract_financial_figure_regex(text, keywords):
    """
    Fallback function using Regex to find the most likely financial figure (in millions)
    near a list of keywords. Tries to handle basic negative signs.
    
    Args:
        text (str): The text to search within.
        keywords (list): A list of keywords to search for.

    Returns:
        float or None: The extracted value in millions, or None if not found/parsed.
    """
    # Regex pattern: Optional currency, optional space, optional parens for negative, 
    # number with commas/decimals, optional space, unit (million/billion/thousand).
    num_pattern = r'[\$€£]?\s?\(?(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\)?\s*(million|billion|thousand)\b'
    search_window = 250 # Characters around keyword to search
    found_figures = [] # Store potential values and their positions

    for keyword in keywords:
        try:
            # Find all occurrences of the keyword (case-insensitive)
            for match in re.finditer(r'\b' + re.escape(keyword) + r'\b', text, re.IGNORECASE):
                kw_start, _ = match.span()
                # Define search segment around the keyword
                search_start = max(0, kw_start - search_window)
                search_end = min(len(text), kw_start + search_window) # Extend window after keyword
                search_segment = text[search_start:search_end]
                
                # Find all number patterns within this segment
                for num_match in re.finditer(num_pattern, search_segment, re.IGNORECASE):
                    value_str, unit = num_match.groups()
                    num_start_in_segment, _ = num_match.span()
                    
                    # Basic check for negative indicator just before the number or via parentheses
                    is_negative = (num_start_in_segment > 0 and search_segment[num_start_in_segment - 1] == '-') or num_match.group(0).startswith('(')
                    
                    try:
                        value = float(value_str.replace(',', ''))
                        value = -value if is_negative else value # Apply sign
                        
                        # Normalize unit to millions
                        unit_lower = unit.lower() if unit else ""
                        if 'billion' in unit_lower: value *= 1000
                        elif 'thousand' in unit_lower: value /= 1000
                        
                        # Store the found value and its absolute position in the original text
                        position = search_start + num_start_in_segment
                        found_figures.append({'value': value, 'pos': position})
                    except ValueError: 
                        continue # Skip if number conversion fails
        except Exception as e: 
            # Log regex errors but continue trying other keywords
            print(f"Regex warning during keyword '{keyword}' search: {e}")
            continue 
            
    # Heuristic to select the best figure found:
    # Prefer the figure closest *after* the first keyword mention, otherwise closest overall.
    if not found_figures: return None
    
    first_kw_match = re.search(r'\b' + re.escape(keywords[0]) + r'\b', text, re.IGNORECASE)
    first_kw_pos = first_kw_match.start() if first_kw_match else 0
    
    figures_after = [f for f in found_figures if f['pos'] >= first_kw_pos]
    
    if figures_after: 
        best_figure = min(figures_after, key=lambda f: abs(f['pos'] - first_kw_pos))
    else: # If no figures found after the first keyword, take the closest one overall
        best_figure = min(found_figures, key=lambda f: abs(f['pos'] - first_kw_pos))
        
    return best_figure['value']

def parse_press_release_regex(text):
    """
    Fallback parser using Regex. Extracts only key current period figures.
    Does not handle qualitative text, supporting figures, prior periods, or leverage well.
    """
    print("Regex Fallback Activated: Extracting key current period figures only...")
    extracted = defaultdict(lambda: None) # Use defaultdict for safety
    
    # Define keywords for core metrics
    extracted['revenue_current'] = extract_financial_figure_regex(text, ["revenue", "total revenue", "net sales", "turnover"]) 
    extracted['ebitda_current'] = extract_financial_figure_regex(text, ["ebitda", "adjusted ebitda", "adj. ebitda"]) 
    extracted['fcf_current'] = extract_financial_figure_regex(text, ["free cash flow", "fcf"])
    
    print("Regex Fallback Notice: Qualitative text, supporting figures, prior periods, and leverage usually require manual input when using this method.")
    return extracted

# --- BASIC KEYWORD FALLBACK for Text Analysis ---
def analyze_drivers_fallback(text):
    """
    Fallback function for analyzing driver text using simple keyword spotting.
    """
    if not text or text.strip().lower() == 'n/a': 
        return "<i>(No text provided for fallback analysis)</i>"
    
    text_lower = text.lower()
    # Simplified keywords for broader matching
    keyword_themes = {
        "Volume/Demand": ["volume", "demand", "unit", "subscriber"], 
        "Price/Mix": ["price", "pricing", "mix", "rate", "yield", "asp"], 
        "Cost Control": ["cost", "expense", "efficiency", "saving", "synergies", "margin", "opex", "cogs"], 
        "M&A/Divestitures": ["acquisition", "divestiture", "merger", "bolt-on"],
        "FX/Rates": ["fx", "foreign exchange", "currency", "interest rate", "translation"], 
        "Capex": ["capex", "capital expenditure", "investment"], 
        "Working Capital": ["working capital", "inventory", "receivables", "payables", "wc"], 
        "Debt/Leverage": ["debt", "borrowing", "leverage", "refinancing", "interest expense"],
        "Product/Market": ["product", "launch", "market", "competition", "share", "segment"]
    }
    
    found_themes = [theme for theme, words in keyword_themes.items() if any(word in text_lower for word in words)]
    
    if not found_themes: 
        return "<i>(Fallback analysis: No specific financial driver keywords detected)</i>"
    else:
        return f"<i>(Fallback analysis: Text mentions themes like: {', '.join(found_themes)})</i>"

# --- TRANSFORMER IMPLEMENTATIONS ---
# These functions use the loaded Hugging Face pipelines for more advanced processing.

def parse_financial_answer(answer_text, is_qualitative=False):
    """
    Parses the answer string from the QA model.
    If is_qualitative is True, returns the cleaned text.
    Otherwise, attempts to parse a financial number (returning float in millions).
    Returns None if parsing fails.
    """
    if not answer_text: return None
    
    if is_qualitative: 
        # Basic text cleanup for qualitative answers
        return answer_text.strip() 
        
    # Numeric Parsing Logic:
    # Normalize text: lowercase, remove common prefixes/suffixes/currency symbols
    text = answer_text.lower().replace('approx.','').replace('approximately','').strip()
    text = re.sub(r'[\$€£]', '', text).strip() # Remove currency symbols
    text = re.sub(r'\s+(dollars|euros|pounds)\b','', text) # Remove currency words
    text = text.replace('(','-').replace(')','') # Convert parenthesis negatives to minus sign
    
    # Regex to find number and optional unit (million, billion, thousand)
    num_pattern = r'([-+]?\d{1,3}(?:,\d{3})*(?:\.\d+)?)\s*(million|billion|thousand|mn|bn|k)?'
    match = re.search(num_pattern, text)
    
    value_str = None
    unit = ""
    if match: # Found number with optional unit
        value_str, unit_match = match.groups()
        unit = unit_match if unit_match else ""
    else: # Attempt to find just a number if pattern with unit fails
        match = re.search(r'([-+]?\d{1,3}(?:,\d{3})*(?:\.\d+)?)', text)
        if match: 
            value_str = match.group(1)
            # No unit found, assume millions by default for finance context
            
    if not value_str: return None # No number found

    # Convert string to float
    try: value = float(value_str.replace(',', ''))
    except ValueError: return None # Not a valid number string

    # Normalize value to millions based on unit
    unit = unit.lower()
    if 'billion' in unit or unit == 'bn': value *= 1000
    elif 'thousand' in unit or unit == 'k': value /= 1000
    # Assumes 'million', 'mn', or no unit implies millions
    
    return value # Return value normalized to millions

def run_qa_query(qa_pipeline, question_list, context, key, status_widget, q_ran_count, q_total_to_run):
    """
    Helper function to run multiple question variations for a single extraction key 
    using the provided QA pipeline. Selects the best answer based on confidence score.

    Args:
        qa_pipeline: Initialized Hugging Face QA pipeline.
        question_list (list): List of question strings for this key.
        context (str): The text context (press release snippet).
        key (str): The dictionary key to store the result under (e.g., 'revenue_current').
        status_widget: The ipywidgets HTML widget to display progress.
        q_ran_count (int): Counter for total questions run so far.
        q_total_to_run (int): Total number of question variations across all keys.

    Returns:
        tuple: (best_answer, updated_q_ran_count) 
               best_answer is the parsed value (float or str) or None.
    """
    best_answer = None
    highest_score = -1 # Initialize with invalid score
    is_qualitative = "text" in key # Determine if we expect text or a number

    # Iterate through different phrasings of the question for robustness
    for q_idx, q in enumerate(question_list):
        q_ran_count += 1
        status_widget.value = f"<span style='color: blue;'>Status: Running QA ({q_ran_count}/{q_total_to_run}) for '{key}' (Var {q_idx+1})...</span>"
        
        try:
            # Run the QA pipeline
            # handle_impossible_answer=True lets model indicate if answer isn't in context
            result = qa_pipeline(question=q, context=context, handle_impossible_answer=True) 
            
            current_answer = result.get('answer') # Get the answer text
            current_score = result.get('score', 0) # Get the confidence score

            print(f"  Q: {q} -> A: '{current_answer}' (Score: {current_score:.3f})") # Debug output
            
            # Check if answer is non-empty and meets minimum confidence threshold
            if current_answer and current_score > QA_SCORE_THRESHOLD: 
                # Parse the answer (numeric or return text if qualitative)
                parsed_value = parse_financial_answer(current_answer, is_qualitative=is_qualitative)
                
                if parsed_value is not None: # Parsing successful (includes valid text)
                    # If this answer has higher confidence, store it as the best one found so far for this key
                    if current_score > highest_score:
                        highest_score = current_score
                        best_answer = parsed_value
                        print(f"    -> Keeping answer for {key}. Score: {highest_score:.3f}. Parsed: {'(text)' if is_qualitative else best_answer}")
                else:
                    # Parsing failed (e.g., couldn't extract number from numeric answer)
                    print(f"    - Could not parse {'number' if not is_qualitative else 'text'} from answer.")
            else:
                # Low confidence or model indicated no answer found in context
                 print(f"    - Low confidence score or no answer found.")

        except Exception as e:
            # Log errors during pipeline execution but continue trying other questions/keys
            print(f"QA Pipeline Error during question '{q}': {e}")
        
        time.sleep(0.05) # Small delay to prevent overwhelming resources/rate limits if applicable
        
    return best_answer, q_ran_count


def parse_press_release_transformer(text, status_widget):
    """
    Uses the Transformer QA pipeline to extract financial figures, qualitative drivers, 
    and supporting data points from the press release text.

    Args:
        text (str): The press release text.
        status_widget: The ipywidgets HTML widget for status updates.

    Returns:
        defaultdict: Dictionary containing extracted values (or None). Keys match UI inputs/estimations.
    """
    qa_pipeline = pipelines.get("qa")
    if not qa_pipeline: 
        raise ValueError("QA model is required but not loaded.")

    # Truncate long text to fit model context window limits (heuristic)
    text_context = text[:QA_CONTEXT_MAX_CHARS] if len(text) > QA_CONTEXT_MAX_CHARS else text
    if len(text) > QA_CONTEXT_MAX_CHARS: 
        print(f"Warning: Input text truncated to {QA_CONTEXT_MAX_CHARS} characters for QA model context.")
        status_widget.value = f"Status: Text truncated to {QA_CONTEXT_MAX_CHARS} chars for QA model."
        
    # Define questions for QA model - grouped by target information type
    # Using defaultdict(list) allows appending multiple question variations easily
    questions = defaultdict(list) 
    
    # --- Core Financials (Current & Prior) ---
    # Add multiple phrasings for robustness against variations in press release language
    questions['revenue_current'].extend(["What was total revenue for the latest reporting period?", "What were net sales for the current period?", "Current period revenue?"])
    questions['revenue_prior'].extend(["What was total revenue for the comparable prior year period?", "What were net sales one year ago?", "Prior year period revenue?"])
    questions['ebitda_current'].extend(["What was Adjusted EBITDA for the latest reporting period?", "What was EBITDA for the current period?", "Current Adj. EBITDA?"])
    questions['ebitda_prior'].extend(["What was Adjusted EBITDA for the comparable prior year period?", "What was EBITDA one year ago?", "Prior year Adj. EBITDA?"])
    questions['fcf_current'].extend(["What was Free Cash Flow (FCF) for the latest reporting period?", "What was FCF in the current period?", "Current Free Cash Flow?"])
    questions['fcf_prior'].extend(["What was Free Cash Flow (FCF) for the comparable prior year period?", "What was FCF one year ago?", "Prior year Free Cash Flow?"])
    
    # --- Qualitative Drivers/Factors ---
    # These keys end in '_text' to signal qualitative answer parsing
    questions['revenue_drivers_text'].extend(["Why did revenue change year-over-year?", "What were the main drivers for revenue performance?", "What factors impacted net sales?"])
    questions['ebitda_drivers_text'].extend(["Why did EBITDA change?", "What were the main drivers for EBITDA performance?", "What factors impacted Adjusted EBITDA margin?"])
    questions['fcf_drivers_text'].extend(["Why did Free Cash Flow change?", "What factors impacted free cash flow generation?", "What drove the change in FCF?"])
    questions['leverage_drivers_text'].extend(["Why did leverage change?", "What factors impacted the net debt to EBITDA ratio?", "What drove the change in net debt?"])

    # --- Supporting Figures (for Estimation & Context) ---
    # Use common accounting terms. Add variations if needed.
    questions['cogs_current'].extend(["What was Cost of Goods Sold (COGS) in the current period?", "What were cost of sales?"])
    questions['cogs_prior'].extend(["What was Cost of Goods Sold (COGS) in the prior year period?", "What were cost of sales one year ago?"])
    questions['opex_current'].extend(["What were Operating Expenses (OpEx) in the current period?", "What was SG&A expense?", "Selling, general and administrative expense?"]) 
    questions['opex_prior'].extend(["What were Operating Expenses (OpEx) in the prior year period?", "What was SG&A expense one year ago?"])
    questions['da_current'].extend(["What was Depreciation and Amortization (D&A) in the current period?", "Current D&A expense?"]) # D&A might be harder to find explicitly
    questions['da_prior'].extend(["What was Depreciation and Amortization (D&A) in the prior year period?", "Prior year D&A expense?"])
    questions['op_income_current'].extend(["What was Operating Income or EBIT in the current period?", "Current Operating Income?"])
    questions['op_income_prior'].extend(["What was Operating Income or EBIT in the prior year period?", "Prior year Operating Income?"])
    questions['ocf_current'].extend(["What was Net Cash from Operating Activities (OCF) in the current period?", "What was cash flow from operations?"])
    questions['ocf_prior'].extend(["What was Net Cash from Operating Activities (OCF) in the prior year period?", "What was cash flow from operations one year ago?"])
    questions['capex_current'].extend(["What was Capital Expenditure (Capex) in the current period?", "What were purchases of property, plant, and equipment?"])
    questions['capex_prior'].extend(["What was Capital Expenditure (Capex) in the prior year period?", "What were capital expenditures one year ago?"])
    questions['debt_total_current'].extend(["What was Total Debt at the end of the current period?", "What were total borrowings?"])
    # Leverage Ratio might be stated directly
    questions['leverage_current'].extend(["What was the Net Debt to EBITDA ratio?", "What was the reported leverage ratio?"])
        
    # --- Execute QA Queries ---
    extracted = defaultdict(lambda: None) # Initialize results dictionary
    q_total_to_run = sum(len(v) for v in questions.values()) # Calculate total number of questions to ask
    q_ran_count = 0 # Initialize counter

    status_widget.value = "<span style='color: blue;'>Status: Running Expanded QA model queries...</span>"
    print(f"Starting Transformer QA for {len(questions)} target data points ({q_total_to_run} total question variations)...")

    # Loop through each target data key and its list of question variations
    for key, question_list in questions.items():
        best_answer_for_key, q_ran_count = run_qa_query(
            qa_pipeline, question_list, text_context, key, 
            status_widget, q_ran_count, q_total_to_run
        )
        extracted[key] = best_answer_for_key # Store the best answer found for this key
            
    status_widget.value = "<span style='color: green;'>Status: Transformer QA processing complete.</span>"
    print(f"Finished QA. Extracted data contains {len([v for v in extracted.values() if v is not None])} non-empty values.")
    # Optional: print raw extracted dictionary for debugging
    # print(f"Extracted data (raw): {dict(extracted)}") 
    return extracted


# --- Transformer Analysis Function ---
def analyze_drivers_transformer(text, status_widget):
    """
    Uses loaded Transformer pipelines (Summarizer, Zero-Shot, Sentiment) 
    to analyze the provided qualitative text (drivers/factors).

    Args:
        text (str): The text to analyze.
        status_widget: The ipywidgets HTML widget for status updates.

    Returns:
        str: An HTML formatted string summarizing the analysis results.
    """
    if not text or text.strip().lower() == 'n/a': 
        return "<i>(No input text provided for AI analysis)</i>"
    
    analysis_parts = {} # Dictionary to store results from different models
    status_widget.value = "<span style='color: blue;'>Status: Analyzing driver/factor text...</span>"
    
    # --- 1. Summarization ---
    summarizer_pipeline = pipelines.get("summarizer")
    if summarizer_pipeline:
        status_widget.value = "<span style='color: blue;'>Status: Analyzing text (Summarization...)</span>"
        try:
            # Generate a concise summary
            summary = summarizer_pipeline(text, max_length=80, min_length=15, do_sample=False)[0]['summary_text']
            analysis_parts["Summary"] = f"<i>{html.escape(summary)}</i>" # Escape summary text
        except Exception as e: 
            print(f"Summarization pipeline failed: {e}")
            analysis_parts["Summary"] = "<i>N/A - Summarization Error</i>"
    else: 
        analysis_parts["Summary"] = "<i>(Summarizer model not available)</i>"

    # --- 2. Zero-Shot Classification (Theme Identification) ---
    zero_shot_pipeline = pipelines.get("zero_shot")
    if zero_shot_pipeline:
        status_widget.value = "<span style='color: blue;'>Status: Analyzing text (Theme Classification...)</span>"
        try:
            # Truncate text if potentially too long for classifier's context window
            text_trunc = text[:TEXT_ANALYSIS_MAX_CHARS_ZS] if len(text) > TEXT_ANALYSIS_MAX_CHARS_ZS else text
            if not text_trunc.strip(): raise ValueError("Text is empty after truncation")

            # Classify text against predefined financial themes, allowing multiple labels
            zs_results = zero_shot_pipeline(text_trunc, candidate_labels=ZERO_SHOT_LABELS, multi_label=True) 
            
            # Filter themes by confidence threshold and sort by score
            sorted_themes = sorted(zip(zs_results['labels'], zs_results['scores']), key=lambda item: item[1], reverse=True)
            filtered_themes = [f"{label} ({score:.0%})" for label, score in sorted_themes if score > ZERO_SHOT_CONFIDENCE_THRESHOLD]
            
            if filtered_themes: 
                analysis_parts["Themes"] = html.escape(", ".join(filtered_themes))
            else: 
                analysis_parts["Themes"] = "<i>None identified above threshold</i>"
        except Exception as e: 
            print(f"Zero-shot classification pipeline failed: {e}")
            analysis_parts["Themes"] = "<i>N/A - Classification Error</i>"
    else: 
        analysis_parts["Themes"] = "<i>(Classifier model not available)</i>"

    # --- 3. Sentiment Analysis ---
    sentiment_pipeline = pipelines.get("sentiment")
    if sentiment_pipeline:
        status_widget.value = "<span style='color: blue;'>Status: Analyzing text (Sentiment...)</span>"
        try:
            # Basic character-based chunking for long text (more robust token-based chunking is complex)
            chunks = [text[i:i+TEXT_ANALYSIS_MAX_CHARS_SENTIMENT] for i in range(0, len(text), TEXT_ANALYSIS_MAX_CHARS_SENTIMENT)]
            sentiments = [] # Store label from each chunk
            scores = []     # Store score from each chunk
            
            print(f"Analyzing sentiment across {len(chunks)} chunk(s)...")
            for chunk in chunks:
                 if not chunk.strip(): continue # Skip empty chunks
                 sentiment_result = sentiment_pipeline(chunk)[0] # Get result for the chunk
                 sentiments.append(sentiment_result['label'])
                 scores.append(sentiment_result['score']) 

            # Aggregate results (simple majority vote for label, average score for that label)
            if sentiments:
                overall_sentiment = max(set(sentiments), key=sentiments.count) # Most frequent label
                # Calculate average score ONLY for the chunks matching the majority sentiment
                avg_score = sum(s for s, lab in zip(scores, sentiments) if lab == overall_sentiment) / sentiments.count(overall_sentiment)
                analysis_parts["Sentiment"] = f"{overall_sentiment.capitalize()} (Avg. Score: {avg_score:.1%})" 
            else:
                 analysis_parts["Sentiment"] = "<i>N/A - No text analyzed</i>"

        except Exception as e: 
            print(f"Sentiment analysis pipeline failed: {e}")
            analysis_parts["Sentiment"] = "<i>N/A - Sentiment Error</i>"
    else: 
        analysis_parts["Sentiment"] = "<i>(Sentiment model not available)</i>"

    # --- Format Output ---
    status_widget.value = "<span style='color: blue;'>Status: Formatting driver analysis...</span>"
    # Build HTML list from the analysis parts dictionary
    output_str = "<ul style='margin-top: 0px; margin-bottom: 5px; padding-left: 20px; font-size: 0.9em;'>"
    if "Summary" in analysis_parts: output_str += f"<li><b>Summary:</b> {analysis_parts['Summary']}</li>"
    if "Themes" in analysis_parts: output_str += f"<li><b>Potential Themes:</b> {analysis_parts['Themes']}</li>"
    if "Sentiment" in analysis_parts: output_str += f"<li><b>Overall Sentiment:</b> {analysis_parts['Sentiment']}</li>"
    output_str += "</ul>"
    
    # Return formatted HTML string, or a failure message if no analysis was possible
    return output_str if analysis_parts else "<i>(AI text analysis could not be performed)</i>"

# --- UI Widgets Setup ---
# Define styles and layouts for consistent appearance
style = {'description_width': 'initial'} # Allow labels to take needed width
layout_half = widgets.Layout(width='48%') # For side-by-side number inputs
layout_full = widgets.Layout(width='98%') # For full-width elements
layout_text_area = widgets.Layout(width='98%', height='100px') # Increased height for driver text

# Section 1: Press Release Input
pr_input_area = widgets.Textarea(
    description="Paste Press Release Text:", 
    placeholder="Paste full earnings press release text here...\nThe AI will attempt to extract key figures and qualitative drivers.", 
    layout=widgets.Layout(width='98%', height='200px'), # Larger area for pasting
    style=style)
parse_button = widgets.Button(
    description="Parse Press Release", 
    button_style='info', 
    icon='paste', 
    tooltip="Attempt to extract figures & drivers using loaded models or Regex fallback")
# Output area for messages specifically during parsing
parse_output_area = widgets.Output() 

# Section 2: Manual Input / Verification Fields
# Revenue
revenue_current_input = widgets.FloatText(description="Current Revenue ($mm):", placeholder='e.g., 1500.5', style=style, layout=layout_half)
revenue_prior_input = widgets.FloatText(description="Prior Revenue ($mm):", placeholder='e.g., 1400.0', style=style, layout=layout_half)
revenue_drivers_input = widgets.Textarea(description="Revenue Drivers/Factors:", placeholder="(Auto-populated or Manual) Describe reasons for change, segment performance, KPIs...", style=style, layout=layout_text_area)
# EBITDA
ebitda_current_input = widgets.FloatText(description="Current EBITDA ($mm):", placeholder='e.g., 350.0', style=style, layout=layout_half)
ebitda_prior_input = widgets.FloatText(description="Prior EBITDA ($mm):", placeholder='e.g., 310.0', style=style, layout=layout_half)
ebitda_drivers_input = widgets.Textarea(description="EBITDA Drivers/Factors:", placeholder="(Auto-populated or Manual) Explain EBITDA change, margin drivers, cost items...", style=style, layout=layout_text_area)
# FCF
fcf_current_input = widgets.FloatText(description="Current FCF ($mm):", placeholder='e.g., 150.0', style=style, layout=layout_half)
fcf_prior_input = widgets.FloatText(description="Prior FCF ($mm):", placeholder='e.g., 120.0', style=style, layout=layout_half)
fcf_drivers_input = widgets.Textarea(description="FCF Drivers/Factors:", placeholder="(Auto-populated or Manual) Explain FCF change, OCF drivers, capex, working capital...", style=style, layout=layout_text_area)
# Leverage
leverage_current_input = widgets.FloatText(description="Current Leverage (x):", placeholder='e.g., 2.5 (Net Debt/EBITDA)', style=style, layout=layout_half)
leverage_prior_input = widgets.FloatText(description="Prior Leverage (x):", placeholder='e.g., 2.8', style=style, layout=layout_half)
leverage_drivers_input = widgets.Textarea(description="Leverage Drivers/Factors:", placeholder="(Auto-populated or Manual) Explain leverage change, debt movements, EBITDA impact...", style=style, layout=layout_text_area)

# Section 3: Analysis Generation
generate_button = widgets.Button(
    description="Generate Analysis Summary", 
    button_style='success', 
    icon='cogs', 
    tooltip="Generate summary using current values and analyze driver text")
# Output area for the final generated report
analysis_output_area = widgets.Output() 

# --- Event Handlers ---
def on_load_models_click(b):
    """Handles the 'Load Transformer Models' button click."""
    # Provide visual feedback during loading
    b.disabled = True; b.description = "Loading Models..."; b.icon = "spinner"
    load_models(load_status_label) # Call the main loading function
    # Reset button state after loading attempt
    b.disabled = False; b.description = "Load Models"; b.icon = "download"
    analysis_status_label.value = "Status: Ready." # Reset analysis status after load attempt

def on_parse_button_click(b):
    """
    Handles the 'Parse Press Release' button click.
    Orchestrates parsing using Transformers (if available) or Regex fallback,
    attempts estimations, and populates the UI fields.
    """
    parse_output_area.clear_output(wait=True) # Clear previous parsing messages
    analysis_output_area.clear_output()      # Clear old analysis report if parsing again
    
    with parse_output_area: # Capture print statements below the parse button
        parse_status_label.value = "<span style='color: blue;'>Status: Parsing press release...</span>"
        print("Initiating press release parsing...")
        pr_text = pr_input_area.value # Get text from UI
        
        # --- Input Validation ---
        if not pr_text or not pr_text.strip():
            print("ERROR: Press release text area is empty. Please paste text and try again.")
            parse_status_label.value = "<span style='color: red;'>Status: Error - Text area empty.</span>"
            return

        # --- Parsing Execution ---
        extracted_data = defaultdict(lambda: None) # Use defaultdict to handle missing keys gracefully
        method_used = "Unknown"
        parse_successful = False

        # Determine which parsing method to use
        use_transformer_qa = TRANSFORMERS_AVAILABLE and models_loaded and pipelines.get("qa")

        if use_transformer_qa:
            try:
                print("Attempting parsing using Transformer QA model...")
                method_used = "Transformer (QA - Enhanced)"
                # Call the transformer parsing function (which includes QA for figures and text)
                extracted_data = parse_press_release_transformer(pr_text, parse_status_label) 
                print("Transformer parsing attempt finished.")
                parse_successful = True # Mark as successful even if some values are None
            except Exception as e:
                # Catch errors during the transformer pipeline execution
                print(f"ERROR: Transformer QA failed during execution: {e}. Falling back to Regex method.")
                parse_status_label.value = f"<span style='color: orange;'>Status: Transformer QA failed. Falling back...</span>"
                method_used = "Regex (Fallback after Transformer Error)"
                # Fallback logic moved below
        
        # If transformer wasn't used or failed, attempt Regex fallback
        if not use_transformer_qa or method_used.startswith("Regex"):
             if not use_transformer_qa:
                 reason = "(Lib unavailable)" if not TRANSFORMERS_AVAILABLE else ("(Models not loaded)" if not models_loaded else "(QA model load fail)")
             else: # Transformer failed during execution
                 reason = "(Transformer Failed)"
                 
             print(f"Using Regex method {reason} (limited extraction)...")
             parse_status_label.value = f"<span style='color: orange;'>Status: Using Regex {reason}...</span>"
             try:
                 # Call the basic Regex parsing function
                 extracted_data = parse_press_release_regex(pr_text) 
                 method_used = "Regex (Fallback)"
                 print("Regex parsing attempt finished.")
                 parse_successful = True # Regex ran, success = True
             except Exception as e_regex:
                 # Catch errors during Regex execution
                 print(f"ERROR: Regex parsing failed: {e_regex}")
                 method_used = "Failed (All methods)"
                 parse_status_label.value = "<span style='color: red;'>Status: All parsing methods failed.</span>"
                 parse_successful = False # Explicitly mark as failed

        # --- Estimation Logic ---
        # Use the 'extracted_data' (from Transformer or Regex) to estimate missing key figures
        final_values_to_populate = dict(extracted_data) # Copy extracted data to potentially add estimates
        estimation_log = [] # Keep track of estimations made

        if parse_successful:
            print("\nAttempting estimations for missing primary figures...")
            est_performed_flag = False # Track if any estimation actually happened
            
            # Define helper to check if needed components are valid numbers
            def _are_valid_nums(*args):
                return all(isinstance(x, (int, float)) and x is not None and not math.isnan(x) for x in args)

            # Estimate EBITDA (Current) = OpIncome + D&A OR Rev - COGS - OpEx + D&A
            if final_values_to_populate.get('ebitda_current') is None:
                opinc, da, rev, cogs, opex = (final_values_to_populate.get(k) for k in ['op_income_current', 'da_current', 'revenue_current', 'cogs_current', 'opex_current'])
                # Prefer OpInc + D&A if available
                if _are_valid_nums(opinc, da):
                    est = opinc + da; final_values_to_populate['ebitda_current'] = est; log_msg = f"EBITDA(C) = OpInc({opinc:.1f}) + D&A({da:.1f}) = {est:.1f}"; estimation_log.append(log_msg); est_performed_flag=True
                # Else try Rev - COGS - OpEx + D&A (treat D&A as 0 if missing)
                elif _are_valid_nums(rev, cogs, opex): 
                    base_opinc = rev - cogs - opex
                    est = base_opinc + (da if _are_valid_nums(da) else 0) # Add D&A if valid, else add 0
                    final_values_to_populate['ebitda_current'] = est; log_msg = f"EBITDA(C) = Rev({rev:.1f})-COGS({cogs:.1f})-OpEx({opex:.1f})+(D&A:{da if _are_valid_nums(da) else 'N/A'}) = {est:.1f}"; estimation_log.append(log_msg); est_performed_flag=True

            # Estimate EBITDA (Prior) - similar logic
            if final_values_to_populate.get('ebitda_prior') is None:
                 opinc_p, da_p = (final_values_to_populate.get(k) for k in ['op_income_prior', 'da_prior'])
                 if _are_valid_nums(opinc_p, da_p):
                    est = opinc_p + da_p; final_values_to_populate['ebitda_prior'] = est; log_msg = f"EBITDA(P) = OpInc_p({opinc_p:.1f}) + D&A_p({da_p:.1f}) = {est:.1f}"; estimation_log.append(log_msg); est_performed_flag=True
                 # Add Rev-COGS-OpEx based estimation for prior if needed

            # Estimate FCF (Current) = OCF - Capex
            if final_values_to_populate.get('fcf_current') is None:
                 ocf, capex = (final_values_to_populate.get(k) for k in ['ocf_current', 'capex_current'])
                 if _are_valid_nums(ocf, capex):
                      # Capex usually reported positive but represents outflow
                      est = ocf - abs(capex) 
                      final_values_to_populate['fcf_current'] = est; log_msg = f"FCF(C) = OCF({ocf:.1f}) - Capex({abs(capex):.1f}) = {est:.1f}"; estimation_log.append(log_msg); est_performed_flag=True

            # Estimate FCF (Prior) - similar logic
            if final_values_to_populate.get('fcf_prior') is None:
                 ocf_p, capex_p = (final_values_to_populate.get(k) for k in ['ocf_prior', 'capex_prior'])
                 if _are_valid_nums(ocf_p, capex_p):
                      est = ocf_p - abs(capex_p)
                      final_values_to_populate['fcf_prior'] = est; log_msg = f"FCF(P) = OCF_p({ocf_p:.1f}) - Capex_p({abs(capex_p):.1f}) = {est:.1f}"; estimation_log.append(log_msg); est_performed_flag=True
                      
            # Estimate Leverage (Current) = Total Debt / (Estimated or Extracted EBITDA)
            if final_values_to_populate.get('leverage_current') is None:
                debt, ebitda = (final_values_to_populate.get(k) for k in ['debt_total_current', 'ebitda_current']) # Use final EBITDA value
                if _are_valid_nums(debt, ebitda) and abs(ebitda) > 1e-6: # Check if components valid and avoid division by zero
                    est = debt / ebitda
                    # Basic sanity check for plausible leverage ratio
                    if 0 < est < 20: # Adjust range if needed
                         final_values_to_populate['leverage_current'] = est; log_msg = f"Leverage(C) = Debt({debt:.1f}) / EBITDA({ebitda:.1f}) = {est:.1f}x"; estimation_log.append(log_msg); est_performed_flag=True
                    else: 
                        log_msg = f"Leverage(C) estimation skipped (calculated ratio {est:.1f}x seems unrealistic)."
                        estimation_log.append(log_msg)

            # Print estimation log if any estimations were made
            if est_performed_flag:
                print("\n--- Estimations Performed (Review Carefully!) ---")
                for log_entry in estimation_log: print(f"- {log_entry}")
                print("-------------------------------------------------")
            else:
                print("\nNo estimations performed (figures found directly or components missing).")

        # --- Populate UI Fields ---
        if parse_successful:
            # Define mapping from data keys to UI widgets
            widget_map = {
                'revenue_current': revenue_current_input, 'revenue_prior': revenue_prior_input,
                'ebitda_current': ebitda_current_input, 'ebitda_prior': ebitda_prior_input,
                'fcf_current': fcf_current_input, 'fcf_prior': fcf_prior_input,
                'leverage_current': leverage_current_input, 'leverage_prior': leverage_prior_input,
                # Qualitative Text Widgets (keys end in '_text')
                'revenue_drivers_text': revenue_drivers_input,
                'ebitda_drivers_text': ebitda_drivers_input,
                'fcf_drivers_text': fcf_drivers_input,
                'leverage_drivers_text': leverage_drivers_input,
            }
            
            print("\nPopulating UI fields from extracted/estimated data:")
            populated_count = 0
            # Loop through mapping and update widget values
            for key, widget in widget_map.items():
                value = final_values_to_populate.get(key) # Get the final value (extracted or estimated)
                # Simple check if estimation likely involved this key's primary metric
                is_estimated = any(key.split('_')[0] in log.lower() for log in estimation_log) 
                
                if value is not None:
                    try:
                        # Format floats slightly for display in FloatText, pass text directly to Textarea
                        if isinstance(widget, widgets.FloatText) and isinstance(value, float):
                            widget.value = float(f"{value:.2f}") # Display with 2 decimals
                        else: 
                            widget.value = value # Assign number or text
                        populated_count += 1
                        # Indicate if value was likely estimated in the log message
                        print(f"  - Set {key}{' (Est.)' if is_estimated else ''}: {value}") 
                    except (ValueError, TypeError) as e: 
                        # Handle potential errors during widget value setting
                        print(f"  - Error setting widget for {key}: {e}")
                        widget.value = None 
                else:
                    # Field not populated if no value found/estimated
                    print(f"  - No value found/estimated for {key}.")

            print(f"\nFinished populating UI ({populated_count} fields filled). Parse Method: {method}")
            print("\n>>> !! CRITICAL !! Please carefully REVIEW and CORRECT ALL auto-populated values (numbers, text, estimations) before generating the final analysis. <<<")
            parse_status_label.value = f"<span style='color: green;'>Status: Parse/Estimate complete ({method}). VERIFY ALL VALUES.</span>"
        
        elif parse_successful: # Parsing ran but yielded no useful data
            print("\nParsing ran but no data could be extracted or estimated. Please enter manually.")
            parse_status_label.value = f"<span style='color: orange;'>Status: Parsing ran ({method}), but no data extracted. Enter manually.</span>"
        
        # else: Status already set for parsing failure cases
        
        analysis_status_label.value = "Status: Ready." # Reset analysis status after parsing attempt

def on_generate_click(b):
    """
    Handles the 'Generate Analysis Summary' button click.
    Retrieves data from UI, performs calculations, analyzes text (using AI or fallback),
    and displays the formatted HTML report.
    Includes syntax fixes from previous iterations.
    """
    analysis_output_area.clear_output(wait=True) # Clear previous analysis report
    
    with analysis_output_area: # Capture print statements below the generate button
        analysis_status_label.value = "<span style='color: blue;'>Status: Generating analysis...</span>"
        print("Generating Financial Performance Summary...")

        # --- 1. Get Values from UI ---
        try:
            # Helper to safely get value and convert to base units (millions * 1e6)
            def get_val_in_units(widget):
                val = widget.value
                # Check if it's a valid number before multiplying
                if isinstance(val, (int, float)) and val is not None and not math.isnan(val):
                    return val * 1_000_000 
                return None # Return None if input is invalid/empty

            # Get numeric values
            rev_c, rev_p = get_val_in_units(revenue_current_input), get_val_in_units(revenue_prior_input)
            ebitda_c, ebitda_p = get_val_in_units(ebitda_current_input), get_val_in_units(ebitda_prior_input)
            fcf_c, fcf_p = get_val_in_units(fcf_current_input), get_val_in_units(fcf_prior_input)
            # Leverage is a ratio, not in millions
            lev_c = leverage_current_input.value if isinstance(leverage_current_input.value, (int, float)) else None
            lev_p = leverage_prior_input.value if isinstance(leverage_prior_input.value, (int, float)) else None

            # Get qualitative inputs (use .get() on dict for safety?)
            qual_inputs = {
                "Rev": revenue_drivers_input.value or "N/A", 
                "EBITDA": ebitda_drivers_input.value or "N/A", 
                "FCF": fcf_drivers_input.value or "N/A", 
                "Lev": leverage_drivers_input.value or "N/A",
            }
        except Exception as e:
             print(f"ERROR retrieving input values from UI: {e}")
             analysis_status_label.value = f"<span style='color: red;'>Status: Error reading input values: {e}</span>"
             return # Stop generation if inputs can't be read

        # --- 2. Analyze Qualitative Text ---
        analysis_status_label.value = "<span style='color: blue;'>Status: Analyzing driver/factor text...</span>"
        qual_analysis = {} # Store results of text analysis
        analysis_method_used = "Basic Keyword Fallback" # Default method name
        
        # Check if required models for AI analysis are loaded
        analysis_models_available = (TRANSFORMERS_AVAILABLE and models_loaded and 
                                     all(pipelines.get(k) for k in ["summarizer", "zero_shot", "sentiment"]))

        if analysis_models_available:
            print("Attempting Transformer-based analysis for driver text...")
            analysis_method_used = "Transformer (AI)" # Update method name
            # Run analysis for each qualitative input field
            for key, text in qual_inputs.items():
                analysis_status_label.value = f"<span style='color: blue;'>Status: AI Analyzing '{key}' text...</span>"
                try: 
                    # Call the transformer analysis function
                    qual_analysis[key] = analyze_drivers_transformer(text, analysis_status_label) 
                except Exception as e: 
                    # If AI analysis fails for one field, log error and use fallback for that field
                    print(f"Transformer analysis failed for {key}: {e}. Using fallback for this item.")
                    qual_analysis[key] = analyze_drivers_fallback(text) 
                    analysis_method_used = "Mixed (AI attempted, some Fallback)" # Indicate mixed results
            analysis_status_label.value = f"<span style='color: blue;'>Status: AI Driver/Factor analysis complete.</span>"
        else:
             # Determine reason for using fallback
             reason = "(Transformers library unavailable)" if not TRANSFORMERS_AVAILABLE else "(Required AI models not loaded)"
             print(f"Using basic keyword analysis {reason}.")
             analysis_status_label.value = f"<span style='color: orange;'>Status: Using Basic Keyword analysis {reason}...</span>"
             # Apply fallback analysis to all qualitative fields
             for key, text in qual_inputs.items(): 
                 qual_analysis[key] = analyze_drivers_fallback(text)
             analysis_status_label.value = "<span style='color: orange;'>Status: Basic driver analysis complete.</span>"

        # --- 3. Perform Calculations ---
        analysis_status_label.value = "<span style='color: blue;'>Status: Performing financial calculations...</span>"
        try:
            # Helper function for calculating YoY change robustly
            def calculate_change(current, prior):
                """Calculates absolute and percentage change, handling None/invalid/zero inputs."""
                # Check if both inputs are valid numbers
                if not all(isinstance(x, (int, float)) and x is not None and not math.isnan(x) for x in [current, prior]): 
                    return None, None # Return None if inputs are invalid
                
                absolute_change = current - prior
                
                # Handle division by zero for percentage change
                if abs(prior) < 1e-9: # Use tolerance for float comparison
                    if abs(current) < 1e-9: percentage_change = 0.0 # Zero to Zero change is 0%
                    elif current > 0: percentage_change = float('inf') # Zero to Positive is Infinite % increase
                    else: percentage_change = float('-inf') # Zero to Negative is Infinite % decrease
                else: 
                    # Calculate percentage change relative to the absolute value of the prior period
                    percentage_change = (absolute_change / abs(prior)) * 100 
                    
                return percentage_change, absolute_change

            # Calculate changes for core metrics
            rev_pc, _ = calculate_change(rev_c, rev_p)
            ebitda_pc, _ = calculate_change(ebitda_c, ebitda_p)
            fcf_pc, _ = calculate_change(fcf_c, fcf_p)
            
            # Calculate leverage change (absolute difference)
            lev_d = (lev_c - lev_p) if all(isinstance(x, (int,float)) and x is not None and not math.isnan(x) for x in [lev_c, lev_p]) else None
            
            # Calculate margins safely, avoiding division by zero revenue
            margin_c = (ebitda_c / rev_c * 100) if rev_c and abs(rev_c) > 1e-9 and ebitda_c is not None else None
            margin_p = (ebitda_p / rev_p * 100) if rev_p and abs(rev_p) > 1e-9 and ebitda_p is not None else None
        
        except Exception as e:
             print(f"ERROR during calculations: {e}")
             analysis_status_label.value = f"<span style='color: red;'>Status: Error during calculations: {e}</span>"
             return # Stop generation if calculations fail

        # --- 4. Format Output HTML ---
        analysis_status_label.value = "<span style='color: blue;'>Status: Formatting output report...</span>"

        # Main report structure
        output_html = f"<h2>Financial Performance Summary</h2><p style='font-size: 0.9em; color: grey;'><i>(Text analysis method: {analysis_method_used})</i></p>"
        
        # Helper function to format the qualitative text and its AI analysis into an HTML list item
        def format_qual_html(label, qual_key):
             """Formats the user text and AI analysis result for the HTML report."""
             text = qual_inputs.get(qual_key, "N/A") # Get user's text input
             analysis_html = qual_analysis.get(qual_key, "") # Get the AI analysis HTML string
             
             # Only include the AI analysis block if it's meaningful (not placeholder/error)
             analysis_block = ""
             if analysis_html and "<i>(" not in analysis_html and "N/A" not in analysis_html:
                  analysis_block = f"<div style='margin-left:15px; margin-top: 3px; font-size:0.9em; color:#333; border-left: 2px solid #eee; padding-left: 5px;'><b>AI Analysis:</b> {analysis_html}</div>"
             elif analysis_html and "<i>(" in analysis_html: # Show fallback message directly
                  analysis_block = f"<div style='margin-left:15px; margin-top: 3px; font-size:0.9em; color:#555;'>{analysis_html}</div>"

             # Escape user's input text to prevent HTML injection issues
             escaped_text = html.escape(text) if text else "N/A"
             # Use <p> tag with pre-wrap to respect user's line breaks in the textarea
             text_display = f"<p style='margin: 2px 0; white-space: pre-wrap;'>{escaped_text}</p>"
             
             # Return the formatted list item
             return f"<li><b>{label}:</b> {text_display}{analysis_block}</li>"

        # --- Generate Revenue Section ---
        output_html += "<h3>Revenue Performance</h3><ul>"
        s1 = "<li>Revenue data incomplete or invalid for YoY comparison.</li>" # Default sentence
        if rev_pc is not None: # Check if percentage change calculation was possible
            if abs(rev_p or 0) < 1e-9: # Check if prior revenue was effectively zero
                s1 = f"<li>Revenue was <strong>{format_currency(rev_c)}</strong> (vs $0.0mm prior; YoY % N/A).</li>"
            else: 
                # Determine direction descriptor
                change_desc = "increased" if rev_pc >= 0 else "decreased" 
                # Override if change is very small (e.g., less than 0.05%)
                if abs(rev_pc) < 0.05: change_desc = "was relatively flat, changing" 
                # Construct the sentence *** SYNTAX CORRECTED HERE ***
                s1 = f"<li>Revenue {change_desc} <strong>{format_percentage(abs(rev_pc))}</strong> YoY to <strong>{format_currency(rev_c)}</strong> (from {format_currency(rev_p)}).</li>"
        elif rev_c is not None: # Handle case where only current revenue is available
            s1 = f"<li>Current Revenue reported as <strong>{format_currency(rev_c)}</strong> (Prior period data unavailable for YoY comparison).</li>"
        output_html += s1
        # Add qualitative drivers/factors analysis
        output_html += format_qual_html("Drivers & Factors", "Rev")
        output_html += "</ul>"

        # --- Generate EBITDA Section ---
        output_html += "<h3>EBITDA & Margin Performance</h3><ul>"
        s1 = "<li>EBITDA data incomplete or invalid for YoY comparison.</li>" # Default sentence
        s2 = "<li>EBITDA margin could not be calculated.</li>" # Default margin sentence
        if ebitda_pc is not None: # Check if YoY calculation was possible
            if abs(ebitda_p or 0) < 1e-9: # Check if prior EBITDA was effectively zero
                s1 = f"<li>EBITDA was <strong>{format_currency(ebitda_c)}</strong> (vs $0.0mm prior; YoY % N/A).</li>"
            else: 
                # Determine direction descriptor
                change_desc = "increased" if ebitda_pc >= 0 else "decreased"
                # Override if change is very small
                if abs(ebitda_pc) < 0.05: change_desc = "was relatively flat, changing"
                # Construct the sentence *** SYNTAX CORRECTED HERE ***
                s1 = f"<li>EBITDA {change_desc} <strong>{format_percentage(abs(ebitda_pc))}</strong> YoY to <strong>{format_currency(ebitda_c)}</strong> (from {format_currency(ebitda_p)}).</li>"
            
            # Generate margin sentence if margins calculable
            if margin_c is not None and margin_p is not None:
                margin_diff = margin_c - margin_p
                margin_change_bps = margin_diff * 100 
                if abs(margin_diff) < 0.05: # Less than 5bps change = stable
                    s2 = f"<li>EBITDA margin remained stable at approximately {format_percentage(margin_c)}.</li>"
                elif margin_diff > 0: # Margin expansion
                    s2 = f"<li>EBITDA margin expanded by {margin_change_bps:.0f} bps YoY to <strong>{format_percentage(margin_c)}</strong> (from {format_percentage(margin_p)}).</li>"
                else: # Margin contraction
                    s2 = f"<li>EBITDA margin contracted by {abs(margin_change_bps):.0f} bps YoY to <strong>{format_percentage(margin_c)}</strong> (from {format_percentage(margin_p)}).</li>"
            elif margin_c is not None: # Only current margin available
                 s2 = f"<li>Current period EBITDA margin was {format_percentage(margin_c)} (Prior period margin unavailable).</li>"
            
        elif ebitda_c is not None: # Handle case where only current EBITDA is available *** SYNTAX CORRECTED HERE ***
             s1 = f"<li>Current EBITDA reported as <strong>{format_currency(ebitda_c)}</strong> (Prior period data unavailable for YoY comparison).</li>"
             # Check if current margin is calculable
             if margin_c is not None: 
                  s2 = f"<li>Current period EBITDA margin was {format_percentage(margin_c)}.</li>"
             # else: s2 retains default "<li>Margin N/A.</li>"

        output_html += s1 # Add EBITDA YoY sentence
        output_html += s2 # Add Margin sentence
        # Add qualitative drivers/factors analysis
        output_html += format_qual_html("Drivers & Factors", "EBITDA")
        output_html += "</ul>"
        
        # --- Generate Free Cash Flow Section ---
        output_html += "<h3>Free Cash Flow Performance</h3><ul>"
        s1 = "<li>Free Cash Flow data incomplete or invalid for YoY comparison.</li>" # Default sentence
        if fcf_pc is not None and fcf_c is not None and fcf_p is not None: # Check calc and inputs valid
            # Handle sign changes and zero cases explicitly for clarity
            prior_is_neg = fcf_p < -1e-9; curr_is_neg = fcf_c < -1e-9; prior_is_zero = abs(fcf_p) < 1e-9
            
            if prior_is_neg and not curr_is_neg: # Negative to Positive/Zero
                s1 = f"<li>FCF improved significantly, turning positive/zero to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
            elif not prior_is_neg and curr_is_neg: # Positive/Zero to Negative
                 s1 = f"<li>FCF declined significantly, turning negative to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
            elif prior_is_zero: # Prior was zero
                 s1 = f"<li>FCF was <strong>{format_currency(fcf_c)}</strong> (vs $0.0mm prior).</li>"
            elif prior_is_neg and curr_is_neg: # Both Negative
                 change_desc = "improved (less negative)" if fcf_c > fcf_p else "worsened (more negative)"
                 s1 = f"<li>FCF {change_desc} to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
            else: # Standard case: Both positive (or current zero, prior positive)
                change_desc = "increased" if fcf_pc >= 0 else "decreased" # Initial direction
                if abs(fcf_pc) < 0.05: change_desc = "was relatively flat, changing" # Override if flat *** SYNTAX CORRECTED HERE ***
                s1 = f"<li>FCF {change_desc} <strong>{format_percentage(abs(fcf_pc))}</strong> YoY to <strong>{format_currency(fcf_c)}</strong> (from {format_currency(fcf_p)}).</li>"
        elif fcf_c is not None: # Only current FCF available
             s1 = f"<li>Current Free Cash Flow reported as <strong>{format_currency(fcf_c)}</strong> (Prior period data unavailable for YoY comparison).</li>"
             
        output_html += s1
        # Add qualitative drivers/factors analysis
        output_html += format_qual_html("Drivers & Factors", "FCF")
        output_html += "</ul>"

        # --- Generate Leverage Section ---
        output_html += "<h3>Leverage Position</h3><ul>"
        s1 = "<li>Leverage data incomplete or invalid for YoY comparison.</li>" # Default sentence
        if lev_d is not None and lev_c is not None and lev_p is not None: # Check calc and inputs valid
            lev_abs_change = abs(lev_d)
            # Use small threshold for stability check
            if lev_abs_change < 0.05: 
                s1 = f"<li>Leverage remained stable at approximately <strong>{format_leverage(lev_c)}</strong> (vs. {format_leverage(lev_p)} prior).</li>"
            elif lev_d > 0: # Leverage increased
                s1 = f"<li>Leverage increased by {lev_abs_change:.1f}x YoY to <strong>{format_leverage(lev_c)}</strong> (from {format_leverage(lev_p)}).</li>"
            else: # Leverage decreased (lev_d < 0)
                s1 = f"<li>Leverage decreased (improved) by {lev_abs_change:.1f}x YoY to <strong>{format_leverage(lev_c)}</strong> (from {format_leverage(lev_p)}).</li>"
        elif lev_c is not None: # Only current Leverage available
             s1 = f"<li>Current Leverage reported as <strong>{format_leverage(lev_c)}</strong> (Prior period data unavailable for YoY comparison).</li>"
             
        output_html += s1
        # Add qualitative drivers/factors analysis
        output_html += format_qual_html("Drivers & Factors", "Lev")
        output_html += "</ul>"
        
        # --- 5. Display Final HTML Report ---
        clear_output(wait=True) # Clear previous console prints within the output area
        display(HTML(output_html)) # Display the rich HTML output
        analysis_status_label.value = "<span style='color: green;'>Status: Analysis complete.</span>"
        print("\nAnalysis generation finished.") # Final console message after HTML is displayed

# --- UI Layout Construction ---
# Create UI elements (buttons, text areas, inputs etc.)
load_models_button = widgets.Button(description="Load AI Models", button_style='warning', icon='download', tooltip="Load advanced AI models (requires install & internet, takes time)")
load_models_button.on_click(on_load_models_click) # Link button to handler

# Arrange Press Release section
pr_section = widgets.VBox([
    widgets.HTML("<b>Optional: Paste Press Release</b>"), 
    pr_input_area, 
    parse_button, 
    parse_status_label, 
    parse_output_area # Output area for parsing messages
])

# Arrange Manual Input section
manual_input_section = widgets.VBox([
     widgets.HTML("<b>Enter / Verify Financial Data ($ millions unless specified):</b>"),
     # Revenue Inputs
     widgets.HTML("<b>Revenue</b>"), 
     widgets.HBox([revenue_current_input, revenue_prior_input]), 
     revenue_drivers_input, 
     # EBITDA Inputs
     widgets.HTML("<hr style='margin: 5px 0; border-top: 1px dashed #ccc;'><b>EBITDA</b>"), 
     widgets.HBox([ebitda_current_input, ebitda_prior_input]), 
     ebitda_drivers_input, 
     # FCF Inputs
     widgets.HTML("<hr style='margin: 5px 0; border-top: 1px dashed #ccc;'><b>Free Cash Flow (FCF)</b>"), 
     widgets.HBox([fcf_current_input, fcf_prior_input]), 
     fcf_drivers_input, 
     # Leverage Inputs
     widgets.HTML("<hr style='margin: 5px 0; border-top: 1px dashed #ccc;'><b>Leverage (x) Ratio</b>"), 
     widgets.HBox([leverage_current_input, leverage_prior_input]), 
     leverage_drivers_input, 
])

# Use Accordion to organize sections
ui_accordion = widgets.Accordion(children=[pr_section, manual_input_section])
ui_accordion.set_title(0, '1. Paste Press Release (Optional)')
ui_accordion.set_title(1, '2. Input / Verify Data')
ui_accordion.selected_index = 1 # Start with Data Input section open

# --- Final App Layout ---
# Assemble all UI components vertically
app_layout = widgets.VBox([
    widgets.HTML("<h2>Financial Analysis Assistant</h2>"),
    widgets.HTML("<b>AI Model Control:</b>"), 
    widgets.HBox([load_models_button, load_status_label]), # Button and status side-by-side
    widgets.HTML("<hr>"),
    ui_accordion, # Input sections
    widgets.HTML("<hr>"),
    generate_button, # Button to generate final report
    analysis_status_label, # Status label for final report generation
    analysis_output_area # Area where final report is displayed
])

# --- Link Buttons to Handlers ---
# Ensure handlers are defined *before* linking them here
parse_button.on_click(on_parse_button_click)
generate_button.on_click(on_generate_click)

# --- Display the UI ---
print("Displaying Financial Analysis Assistant UI...") # Initial message
display(app_layout)

# --- Post-Display Information ---
# Remind user about dependencies if AI features are disabled
if not TRANSFORMERS_AVAILABLE:
    print("\n--------------------------------------------------------------------------")
    print("REMINDER: `transformers` library or backend issue detected.")
    print("Advanced AI parsing/analysis features are disabled.")
    print("Install/verify (`pip install transformers torch` or `tensorflow`) and restart kernel for full functionality.")
    print("Using basic Regex/Keyword analysis as fallback.")
    print("--------------------------------------------------------------------------")

# %%-- End of Single Cell --%%
